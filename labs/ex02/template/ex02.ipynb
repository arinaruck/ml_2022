{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_cost` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = (y - tx @ w)\n",
    "    mse = e.T @ e / (2 * N)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5388.966731774168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(y, tx, np.array([1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "        \n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "            losses[i][j] = compute_loss(y, tx, np.array([w0, w1]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=30.79581141642729, w0*=73.14629258517036, w1*=13.527054108216447, execution time=7.027 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=500)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "      l=loss_star, w0=w0_star, w1=w1_star, t=execution_time))\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0,6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210863151735564"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(84.84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    grad =  -1 / N * tx.T @ e\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-23.293922    -3.47971243]\n",
      "[26.706078    6.52028757]\n"
     ]
    }
   ],
   "source": [
    "print(compute_gradient(y, tx, w=np.array([50, 10])))\n",
    "print(compute_gradient(y, tx, w=np.array([100, 20])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD \n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        w = w - gamma * grad\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2125212.8925597533, w0=-892.6706077997894, w1=901.3479712434988\n",
      "GD iter. 1/49: loss=1721428.2896107903, w0=-796.0741548195998, w1=812.5611453626477\n",
      "GD iter. 2/49: loss=1394362.7612221295, w0=-709.1373471374293, w1=732.6530020698817\n",
      "GD iter. 3/49: loss=1129439.6832273148, w0=-630.8942202234758, w1=660.7356731063924\n",
      "GD iter. 4/49: loss=914851.990051515, w0=-560.4754060009177, w1=596.010077039252\n",
      "GD iter. 5/49: loss=741035.9585791173, w0=-497.09847320061533, w1=537.7570405788256\n",
      "GD iter. 6/49: loss=600244.973086475, w0=-440.0592336803432, w1=485.32930776444186\n",
      "GD iter. 7/49: loss=486204.27483743476, w0=-388.72391811209826, w1=438.1443482314965\n",
      "GD iter. 8/49: loss=393831.30925571214, w0=-342.5221341006779, w1=395.6778846518457\n",
      "GD iter. 9/49: loss=319009.20713451685, w0=-300.9405284903995, w1=357.45806743016\n",
      "GD iter. 10/49: loss=258403.30441634878, w0=-263.517083441149, w1=323.06023193064283\n",
      "GD iter. 11/49: loss=209312.52321463262, w0=-229.83598289682354, w1=292.1021799810774\n",
      "GD iter. 12/49: loss=169548.9904412425, w0=-199.52299240693065, w1=264.23993322646857\n",
      "GD iter. 13/49: loss=137340.52889479656, w0=-172.24130096602704, w1=239.1639111473206\n",
      "GD iter. 14/49: loss=111251.67504217534, w0=-147.6877786692138, w1=216.59549127608742\n",
      "GD iter. 15/49: loss=90119.70342155219, w0=-125.58960860208188, w1=196.28391339197753\n",
      "GD iter. 16/49: loss=73002.8064088474, w0=-105.70125554166316, w1=178.00349329627866\n",
      "GD iter. 17/49: loss=59138.11982855654, w0=-87.80173778728631, w1=161.55111521014967\n",
      "GD iter. 18/49: loss=47907.72369852093, w0=-71.69217180834714, w1=146.7439749326336\n",
      "GD iter. 19/49: loss=38811.102833192104, w0=-57.19356242730189, w1=133.41754868286912\n",
      "GD iter. 20/49: loss=31442.839932275747, w0=-44.144813984361164, w1=121.42376505808109\n",
      "GD iter. 21/49: loss=25474.5469825335, w0=-32.40094038571451, w1=110.62935979577188\n",
      "GD iter. 22/49: loss=20640.229693242287, w0=-21.83145414693253, w1=100.91439505969358\n",
      "GD iter. 23/49: loss=16724.4326889164, w0=-12.318916532028746, w1=92.17092679722312\n",
      "GD iter. 24/49: loss=13552.637115412437, w0=-3.7576326786153444, w1=84.30180536099971\n",
      "GD iter. 25/49: loss=10983.482700874229, w0=3.947522789456717, w1=77.21959606839863\n",
      "GD iter. 26/49: loss=8902.467625098277, w0=10.882162710721573, w1=70.84560770505766\n",
      "GD iter. 27/49: loss=7216.845413719757, w0=17.12333863985994, w1=65.10901817805079\n",
      "GD iter. 28/49: loss=5851.491422503157, w0=22.740396976084472, w1=59.94608760374461\n",
      "GD iter. 29/49: loss=4745.55468961771, w0=27.79574947868655, w1=55.299450086869044\n",
      "GD iter. 30/49: loss=3849.7459359805002, w0=32.34556673102842, w1=51.11747632168104\n",
      "GD iter. 31/49: loss=3124.1408455343594, w0=36.4404022581361, w1=47.35369993301184\n",
      "GD iter. 32/49: loss=2536.4007222729856, w0=40.12575423253302, w1=43.96630118320956\n",
      "GD iter. 33/49: loss=2060.331222431273, w0=43.44257100949024, w1=40.91764230838751\n",
      "GD iter. 34/49: loss=1674.7149275594861, w0=46.427706108751735, w1=38.173849321047655\n",
      "GD iter. 35/49: loss=1362.3657287133385, w0=49.11432769808708, w1=35.70443563244179\n",
      "GD iter. 36/49: loss=1109.362877647959, w0=51.532287128488896, w1=33.481963312696514\n",
      "GD iter. 37/49: loss=904.4305682850019, w0=53.70845061585052, w1=31.481738224925763\n",
      "GD iter. 38/49: loss=738.4353977010064, w0=55.66699775447599, w1=29.68153564593209\n",
      "GD iter. 39/49: loss=603.9793095279701, w0=57.42969017923892, w1=28.061353324837786\n",
      "GD iter. 40/49: loss=495.06987810781095, w0=59.01611336152555, w1=26.60318923585291\n",
      "GD iter. 41/49: loss=406.85323865748194, w0=60.44389422558351, w1=25.29084155576652\n",
      "GD iter. 42/49: loss=335.3977607027154, w0=61.72889700323568, w1=24.109728643688772\n",
      "GD iter. 43/49: loss=277.51882355935464, w0=62.885399503122635, w1=23.0467270228188\n",
      "GD iter. 44/49: loss=230.63688447323236, w0=63.92625175302089, w1=22.090025564035823\n",
      "GD iter. 45/49: loss=192.66251381347334, w0=64.86301877792933, w1=21.228994251131144\n",
      "GD iter. 46/49: loss=161.90327357906844, w0=65.70610910034691, w1=20.454066069516934\n",
      "GD iter. 47/49: loss=136.9882889892007, w0=66.46489039052274, w1=19.756630706064144\n",
      "GD iter. 48/49: loss=116.80715147140764, w0=67.14779355168099, w1=19.12893887895663\n",
      "GD iter. 49/49: loss=100.46043008199528, w0=67.7624063967234, w1=18.564016234559872\n",
      "GD: execution time=0.034 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([-1000, 1000])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75c8f8d008a4bc6b76c94914597a93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses, gd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    return compute_gradient(y, tx, w)\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "            \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    batches = batch_iter(y, tx, batch_size, num_batches=max_iters, shuffle=True)\n",
    "    \n",
    "    for n_iter, (y_batch, tx_batch) in enumerate(batches):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        grad = compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "        w = w - gamma * grad\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=5658.544448876833, w0=6.472472932569706, w1=-6.18858934860241\n",
      "SGD iter. 1/49: loss=4964.738597970561, w0=13.060556067697805, w1=-4.6482063154730024\n",
      "SGD iter. 2/49: loss=4061.9436755760316, w0=18.20167569355962, w1=-5.104287882414923\n",
      "SGD iter. 3/49: loss=3483.2140439136497, w0=21.511204704303417, w1=-8.072158524239986\n",
      "SGD iter. 4/49: loss=3252.2987175245294, w0=24.53774413616908, w1=-10.329343427606481\n",
      "SGD iter. 5/49: loss=3052.850002302021, w0=31.962263553334356, w1=-5.517713145323875\n",
      "SGD iter. 6/49: loss=2163.413276075111, w0=33.23533510121845, w1=-7.230223452725145\n",
      "SGD iter. 7/49: loss=2130.3467422013728, w0=36.023924239483435, w1=-8.169059396845839\n",
      "SGD iter. 8/49: loss=1954.4600744710071, w0=42.823400716686606, w1=0.967547626803201\n",
      "SGD iter. 9/49: loss=1158.9437599832504, w0=44.40704680963298, w1=-1.7116459023190345\n",
      "SGD iter. 10/49: loss=1143.431009156698, w0=44.28760968961782, w1=-1.4928587810194967\n",
      "SGD iter. 11/49: loss=1143.3911279969643, w0=47.637259678676365, w1=0.22758595352864863\n",
      "SGD iter. 12/49: loss=906.0364519515883, w0=49.0938322653897, w1=-0.6661727048515769\n",
      "SGD iter. 13/49: loss=858.6983734810498, w0=53.17721815103363, w1=4.058854546698984\n",
      "SGD iter. 14/49: loss=554.2068871869748, w0=56.483755972161696, w1=7.312597139482188\n",
      "SGD iter. 15/49: loss=372.66859979870924, w0=57.06618594526513, w1=6.63534279754078\n",
      "SGD iter. 16/49: loss=363.1933695560129, w0=57.81765951371701, w1=6.262516753262326\n",
      "SGD iter. 17/49: loss=344.8453114019419, w0=58.41659812546622, w1=5.733531562927148\n",
      "SGD iter. 18/49: loss=335.2292093128988, w0=60.88523639861446, w1=7.437611533333174\n",
      "SGD iter. 19/49: loss=239.30855587269784, w0=62.153440843162784, w1=7.480679863146701\n",
      "SGD iter. 20/49: loss=207.98081984113261, w0=63.91061407931584, w1=9.103650323824015\n",
      "SGD iter. 21/49: loss=150.65648140479493, w0=64.04566206435507, w1=8.98906771785668\n",
      "SGD iter. 22/49: loss=149.29315580569295, w0=65.42310814068107, w1=10.077600776463383\n",
      "SGD iter. 23/49: loss=114.0205681144155, w0=67.10714663845164, w1=12.695908929133507\n",
      "SGD iter. 24/49: loss=73.03181022061179, w0=67.37098456867442, w1=12.22770565733163\n",
      "SGD iter. 25/49: loss=71.54409616683738, w0=67.52211726691054, w1=12.20101024248266\n",
      "SGD iter. 26/49: loss=69.79510178113867, w0=68.1421888457634, w1=13.235237641458495\n",
      "SGD iter. 27/49: loss=58.96664667245759, w0=68.05802157592608, w1=13.294127714094795\n",
      "SGD iter. 28/49: loss=59.75526712921546, w0=67.99509571484481, w1=13.321508004980346\n",
      "SGD iter. 29/49: loss=60.39680169421285, w0=68.4231873116015, w1=12.768987696495909\n",
      "SGD iter. 30/49: loss=57.33432123581631, w0=68.96862367929543, w1=12.726404100378556\n",
      "SGD iter. 31/49: loss=52.096542775423565, w0=68.26910491149759, w1=12.698051626246022\n",
      "SGD iter. 32/49: loss=59.2104868513854, w0=69.31052391026164, w1=13.67572318992563\n",
      "SGD iter. 33/49: loss=46.60435084664059, w0=69.63873381525366, w1=13.191092375089173\n",
      "SGD iter. 34/49: loss=44.885449806599524, w0=69.0839336432851, w1=13.468651446414931\n",
      "SGD iter. 35/49: loss=48.9884122231542, w0=68.86147317102086, w1=13.40944683074908\n",
      "SGD iter. 36/49: loss=51.184301696198006, w0=69.02921227170737, w1=13.532951367937445\n",
      "SGD iter. 37/49: loss=49.36381689540296, w0=69.94679192326272, w1=13.728748651514996\n",
      "SGD iter. 38/49: loss=41.427580009682536, w0=69.99519692879052, w1=13.696079529704747\n",
      "SGD iter. 39/49: loss=41.123003722079666, w0=71.02823786745735, w1=14.08017062517245\n",
      "SGD iter. 40/49: loss=34.22431312472719, w0=70.85952279612053, w1=14.20146729074082\n",
      "SGD iter. 41/49: loss=35.05021657350644, w0=71.26111604892665, w1=15.161432670554412\n",
      "SGD iter. 42/49: loss=33.3794749551694, w0=71.58038472055205, w1=15.547966423326056\n",
      "SGD iter. 43/49: loss=32.6468577421754, w0=71.81524386655117, w1=15.611838073780453\n",
      "SGD iter. 44/49: loss=31.87926117358443, w0=71.44101352974396, w1=15.719216050287729\n",
      "SGD iter. 45/49: loss=33.63480536078515, w0=72.30386623927613, w1=14.878763107604065\n",
      "SGD iter. 46/49: loss=29.213988647300248, w0=72.21548254858152, w1=14.780281989336471\n",
      "SGD iter. 47/49: loss=29.38693049308271, w0=71.56135100427288, w1=15.259426630677074\n",
      "SGD iter. 48/49: loss=32.18980508579156, w0=71.52252042391245, w1=15.299000947454976\n",
      "SGD iter. 49/49: loss=32.41573969623977, w0=71.22538645511115, w1=14.98361073687929\n",
      "SGD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03d7999c022407ca0d261776d67961a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses, sgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=5739.670229071705, w0=51.847464098448434, w1=7.724426406192428\n",
      "GD iter. 1/49: loss=636.5642494031922, w0=67.40170332798299, w1=10.041754328050118\n",
      "GD iter. 2/49: loss=177.2847112330254, w0=72.06797509684336, w1=10.736952704607411\n",
      "GD iter. 3/49: loss=135.9495527977104, w0=73.46785662750146, w1=10.945512217574596\n",
      "GD iter. 4/49: loss=132.22938853853208, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=131.89457375520604, w0=74.01381042445813, w1=11.026850427631796\n",
      "GD iter. 6/49: loss=131.8644404247067, w0=74.0516072257859, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=131.86172842496177, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=131.86148434498472, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=131.86146237778675, w0=74.06736849193958, w1=11.034829706038407\n",
      "GD iter. 10/49: loss=131.86146040073896, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=131.86146022280465, w0=74.06776649225755, w1=11.03488900159354\n",
      "GD iter. 12/49: loss=131.86146020679055, w0=74.06779404612573, w1=11.034893106670435\n",
      "GD iter. 13/49: loss=131.8614602053493, w0=74.06780231228618, w1=11.0348943381935\n",
      "GD iter. 14/49: loss=131.8614602052196, w0=74.06780479213431, w1=11.034894707650423\n",
      "GD iter. 15/49: loss=131.86146020520792, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=131.86146020520687, w0=74.06780575927509, w1=11.034894851738622\n",
      "GD iter. 17/49: loss=131.86146020520675, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=131.86146020520675, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=131.86146020520678, w0=74.06780585234378, w1=11.03489486560434\n",
      "GD iter. 20/49: loss=131.86146020520673, w0=74.06780585415159, w1=11.034894865873673\n",
      "GD iter. 21/49: loss=131.86146020520675, w0=74.06780585469393, w1=11.034894865954472\n",
      "GD iter. 22/49: loss=131.86146020520675, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=131.86146020520675, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=131.86146020520675, w0=74.0678058549201, w1=11.034894865988168\n",
      "GD iter. 25/49: loss=131.86146020520675, w0=74.06780585492449, w1=11.034894865988822\n",
      "GD iter. 26/49: loss=131.86146020520675, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=131.86146020520673, w0=74.06780585492619, w1=11.034894865989077\n",
      "GD iter. 28/49: loss=131.86146020520673, w0=74.06780585492632, w1=11.034894865989095\n",
      "GD iter. 29/49: loss=131.86146020520673, w0=74.06780585492635, w1=11.034894865989099\n",
      "GD iter. 30/49: loss=131.86146020520675, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 31/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 32/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 33/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 34/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 35/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 36/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 37/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 38/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 39/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 40/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 41/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 42/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 43/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 44/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 45/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 46/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 47/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 48/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 49/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD: execution time=0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73c57b62e4048208184ad8ccc04ae0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses, gd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE(y, w) =  |y - Xw| = e$\n",
    "\n",
    "$e_i = |y_i - x_i^T w|$\n",
    "\n",
    "$subgradient MAE(y, w) = g$\n",
    "\n",
    "$g_i = -x_i^T , \\ y_i > x_i^T w$\n",
    "\n",
    "$g_i = [-x_i^T, x_i^T] , \\ y_i = x_i^T w$\n",
    "\n",
    "$g_i = x_i^T, \\ y_i < x_i^Tw$\n",
    "\n",
    "g = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import sin\n",
    "\n",
    "\n",
    "def compute_mae_loss(y, tx, w):\n",
    "    e = y - tx @ w\n",
    "    mae = np.abs(e).mean()\n",
    "    return mae\n",
    "\n",
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = (y - tx @ w)\n",
    "    sign = (e >= 0).reshape(-1, 1) * 2 - 1\n",
    "    grad = -np.ones((1, N)) @ (tx * sign) / N\n",
    "    return grad.squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD \n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_mae_loss(y, tx, w)\n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        w = w - gamma * subgrad\n",
    "        \n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=73.29392200210518, w0=0.7, w1=-7.321432349272072e-16\n",
      "SubGD iter. 1/499: loss=72.59392200210517, w0=1.4, w1=-1.4642864698544144e-15\n",
      "SubGD iter. 2/499: loss=71.89392200210517, w0=2.0999999999999996, w1=-2.1964297047816213e-15\n",
      "SubGD iter. 3/499: loss=71.19392200210518, w0=2.8, w1=-2.9285729397088287e-15\n",
      "SubGD iter. 4/499: loss=70.49392200210517, w0=3.5, w1=-3.660716174636036e-15\n",
      "SubGD iter. 5/499: loss=69.79392200210518, w0=4.2, w1=-4.3928594095632435e-15\n",
      "SubGD iter. 6/499: loss=69.09392200210517, w0=4.9, w1=-5.125002644490451e-15\n",
      "SubGD iter. 7/499: loss=68.39392200210519, w0=5.6000000000000005, w1=-5.857145879417658e-15\n",
      "SubGD iter. 8/499: loss=67.69392200210518, w0=6.300000000000001, w1=-6.5892891143448656e-15\n",
      "SubGD iter. 9/499: loss=66.99392200210517, w0=7.000000000000001, w1=-7.321432349272072e-15\n",
      "SubGD iter. 10/499: loss=66.29392200210518, w0=7.700000000000001, w1=-8.05357558419928e-15\n",
      "SubGD iter. 11/499: loss=65.59392200210517, w0=8.4, w1=-8.785718819126487e-15\n",
      "SubGD iter. 12/499: loss=64.89392200210517, w0=9.1, w1=-9.517862054053694e-15\n",
      "SubGD iter. 13/499: loss=64.19392200210518, w0=9.799999999999999, w1=-1.0250005288980902e-14\n",
      "SubGD iter. 14/499: loss=63.49392200210517, w0=10.499999999999998, w1=-1.0982148523908109e-14\n",
      "SubGD iter. 15/499: loss=62.79392200210517, w0=11.199999999999998, w1=-1.1714291758835316e-14\n",
      "SubGD iter. 16/499: loss=62.09392200210518, w0=11.899999999999997, w1=-1.2446434993762524e-14\n",
      "SubGD iter. 17/499: loss=61.39392200210517, w0=12.599999999999996, w1=-1.3178578228689731e-14\n",
      "SubGD iter. 18/499: loss=60.69392200210518, w0=13.299999999999995, w1=-1.3910721463616939e-14\n",
      "SubGD iter. 19/499: loss=59.99392200210517, w0=13.999999999999995, w1=-1.4642864698544144e-14\n",
      "SubGD iter. 20/499: loss=59.293922002105184, w0=14.699999999999994, w1=-1.5375007933471352e-14\n",
      "SubGD iter. 21/499: loss=58.59392200210518, w0=15.399999999999993, w1=-1.610715116839856e-14\n",
      "SubGD iter. 22/499: loss=57.893922002105185, w0=16.099999999999994, w1=-1.6839294403325767e-14\n",
      "SubGD iter. 23/499: loss=57.19392200210518, w0=16.799999999999994, w1=-1.7571437638252974e-14\n",
      "SubGD iter. 24/499: loss=56.49392200210517, w0=17.499999999999993, w1=-1.830358087318018e-14\n",
      "SubGD iter. 25/499: loss=55.793922002105184, w0=18.199999999999992, w1=-1.903572410810739e-14\n",
      "SubGD iter. 26/499: loss=55.09392200210518, w0=18.89999999999999, w1=-1.9767867343034596e-14\n",
      "SubGD iter. 27/499: loss=54.393922002105185, w0=19.59999999999999, w1=-2.0500010577961803e-14\n",
      "SubGD iter. 28/499: loss=53.69392200210518, w0=20.29999999999999, w1=-2.123215381288901e-14\n",
      "SubGD iter. 29/499: loss=52.99392200210518, w0=20.99999999999999, w1=-2.1964297047816218e-14\n",
      "SubGD iter. 30/499: loss=52.293922002105184, w0=21.69999999999999, w1=-2.2696440282743426e-14\n",
      "SubGD iter. 31/499: loss=51.59392200210519, w0=22.399999999999988, w1=-2.3428583517670633e-14\n",
      "SubGD iter. 32/499: loss=50.893922002105185, w0=23.099999999999987, w1=-2.416072675259784e-14\n",
      "SubGD iter. 33/499: loss=50.19392200210519, w0=23.799999999999986, w1=-2.4892869987525048e-14\n",
      "SubGD iter. 34/499: loss=49.49392200210518, w0=24.499999999999986, w1=-2.5625013222452255e-14\n",
      "SubGD iter. 35/499: loss=48.793922002105184, w0=25.199999999999985, w1=-2.6357156457379462e-14\n",
      "SubGD iter. 36/499: loss=48.093922002105195, w0=25.899999999999984, w1=-2.708929969230667e-14\n",
      "SubGD iter. 37/499: loss=47.39392200210519, w0=26.599999999999984, w1=-2.7821442927233877e-14\n",
      "SubGD iter. 38/499: loss=46.69392200210519, w0=27.299999999999983, w1=-2.855358616216108e-14\n",
      "SubGD iter. 39/499: loss=45.99392200210519, w0=27.999999999999982, w1=-2.928572939708829e-14\n",
      "SubGD iter. 40/499: loss=45.29392200210519, w0=28.69999999999998, w1=-3.0017872632015496e-14\n",
      "SubGD iter. 41/499: loss=44.593922002105195, w0=29.39999999999998, w1=-3.0750015866942704e-14\n",
      "SubGD iter. 42/499: loss=43.89392723059967, w0=30.099859999999982, w1=0.0004404657702774693\n",
      "SubGD iter. 43/499: loss=43.194206925442394, w0=30.799719999999983, w1=0.0008809315405856887\n",
      "SubGD iter. 44/499: loss=42.494486620285116, w0=31.499579999999984, w1=0.001321397310893908\n",
      "SubGD iter. 45/499: loss=41.794801882440076, w0=32.19929999999999, w1=0.002151200058841489\n",
      "SubGD iter. 46/499: loss=41.09536078676492, w0=32.899019999999986, w1=0.0029810028067890695\n",
      "SubGD iter. 47/499: loss=40.396015121762325, w0=33.59859999999998, w1=0.004238399708411862\n",
      "SubGD iter. 48/499: loss=39.696964631836686, w0=34.298039999999986, w1=0.00582382240883199\n",
      "SubGD iter. 49/499: loss=38.99808059302935, w0=34.99747999999999, w1=0.007409245109252119\n",
      "SubGD iter. 50/499: loss=38.29919655422201, w0=35.69691999999999, w1=0.008994667809672247\n",
      "SubGD iter. 51/499: loss=37.60047035260179, w0=36.39607999999999, w1=0.01124804985353109\n",
      "SubGD iter. 52/499: loss=36.90236166793369, w0=37.09495999999999, w1=0.014269124444740816\n",
      "SubGD iter. 53/499: loss=36.20468598163629, w0=37.793699999999994, w1=0.017663499462384047\n",
      "SubGD iter. 54/499: loss=35.5072889013021, w0=38.49215999999999, w1=0.02158797299120177\n",
      "SubGD iter. 55/499: loss=34.81047272559702, w0=39.19019999999999, w1=0.026549981650559756\n",
      "SubGD iter. 56/499: loss=34.11463938511051, w0=39.88739999999999, w1=0.033459020630950874\n",
      "SubGD iter. 57/499: loss=33.42034933030703, w0=40.584039999999995, w1=0.0415535299136332\n",
      "SubGD iter. 58/499: loss=32.72708260590542, w0=41.28025999999999, w1=0.05080738787875296\n",
      "SubGD iter. 59/499: loss=32.035274191106154, w0=41.97507999999999, w1=0.06316953459269514\n",
      "SubGD iter. 60/499: loss=31.346253501120472, w0=42.667939999999994, w1=0.07970663453192255\n",
      "SubGD iter. 61/499: loss=30.660811185738606, w0=43.35925999999999, w1=0.09929003796962779\n",
      "SubGD iter. 62/499: loss=29.97824373392408, w0=44.04889999999999, w1=0.12249682042561978\n",
      "SubGD iter. 63/499: loss=29.29919217002557, w0=44.735739999999986, w1=0.15117673515150715\n",
      "SubGD iter. 64/499: loss=28.625370150150538, w0=45.41991999999998, w1=0.18484712944085602\n",
      "SubGD iter. 65/499: loss=27.956408127884874, w0=46.10073999999998, w1=0.2249017046488733\n",
      "SubGD iter. 66/499: loss=27.293211335702274, w0=46.77847999999998, w1=0.2703080759890575\n",
      "SubGD iter. 67/499: loss=26.63594677549217, w0=47.45243999999998, w1=0.3220564131365024\n",
      "SubGD iter. 68/499: loss=25.98635445566157, w0=48.119959999999985, w1=0.3843602843517057\n",
      "SubGD iter. 69/499: loss=25.34635990054961, w0=48.78257999999998, w1=0.4546014318707077\n",
      "SubGD iter. 70/499: loss=24.71340776639182, w0=49.44141999999998, w1=0.5311991534379218\n",
      "SubGD iter. 71/499: loss=24.08693114448954, w0=50.094659999999976, w1=0.6167864550872327\n",
      "SubGD iter. 72/499: loss=23.469061835298337, w0=50.74159999999998, w1=0.7118294204257591\n",
      "SubGD iter. 73/499: loss=22.86031221944988, w0=51.382239999999975, w1=0.8163783816189143\n",
      "SubGD iter. 74/499: loss=22.260394194603602, w0=52.015879999999974, w1=0.9309819479180697\n",
      "SubGD iter. 75/499: loss=21.67021435798935, w0=52.64223999999997, w1=1.056041039445621\n",
      "SubGD iter. 76/499: loss=21.089713092061288, w0=53.261179999999975, w1=1.1909782249707974\n",
      "SubGD iter. 77/499: loss=20.518395200293856, w0=53.87353999999998, w1=1.3354326069269324\n",
      "SubGD iter. 78/499: loss=19.95484201902196, w0=54.479039999999976, w1=1.488859155423162\n",
      "SubGD iter. 79/499: loss=19.399817277965223, w0=55.07641999999998, w1=1.6526057998941954\n",
      "SubGD iter. 80/499: loss=18.854292127308728, w0=55.664699999999975, w1=1.827199911738598\n",
      "SubGD iter. 81/499: loss=18.318783947893152, w0=56.24345999999998, w1=2.0132129159762755\n",
      "SubGD iter. 82/499: loss=17.79249147952515, w0=56.81479999999998, w1=2.2075986497860676\n",
      "SubGD iter. 83/499: loss=17.27474434540425, w0=57.37633999999998, w1=2.4113762709745252\n",
      "SubGD iter. 84/499: loss=16.766906752678814, w0=57.92975999999998, w1=2.6230481013705376\n",
      "SubGD iter. 85/499: loss=16.26799447974928, w0=58.47407999999998, w1=2.8433267790651695\n",
      "SubGD iter. 86/499: loss=15.777334186667364, w0=59.00957999999998, w1=3.0723309655204143\n",
      "SubGD iter. 87/499: loss=15.294906834780774, w0=59.53569999999998, w1=3.3102924945409606\n",
      "SubGD iter. 88/499: loss=14.820404573025069, w0=60.053559999999976, w1=3.5553517483538837\n",
      "SubGD iter. 89/499: loss=14.354283714893926, w0=60.559939999999976, w1=3.8091706918861212\n",
      "SubGD iter. 90/499: loss=13.8980013928949, w0=61.057499999999976, w1=4.069720751434041\n",
      "SubGD iter. 91/499: loss=13.448823828103757, w0=61.547919999999976, w1=4.335508393726964\n",
      "SubGD iter. 92/499: loss=13.00604419634408, w0=62.02965999999998, w1=4.606989747001095\n",
      "SubGD iter. 93/499: loss=12.57110174936066, w0=62.502719999999975, w1=4.885020142516876\n",
      "SubGD iter. 94/499: loss=12.143380485959367, w0=62.96583999999997, w1=5.168754626653936\n",
      "SubGD iter. 95/499: loss=11.723894837245558, w0=63.41971999999997, w1=5.456484559032101\n",
      "SubGD iter. 96/499: loss=11.313435023601532, w0=63.86463999999997, w1=5.747997496770166\n",
      "SubGD iter. 97/499: loss=10.911156920015078, w0=64.30129999999997, w1=6.043221223968435\n",
      "SubGD iter. 98/499: loss=10.516948122608058, w0=64.72773999999997, w1=6.340354080836974\n",
      "SubGD iter. 99/499: loss=10.133595131038648, w0=65.14381999999996, w1=6.6399452459063895\n",
      "SubGD iter. 100/499: loss=9.760677429923467, w0=65.54995999999996, w1=6.939754306257042\n",
      "SubGD iter. 101/499: loss=9.398674623189917, w0=65.94755999999995, w1=7.240382293155406\n",
      "SubGD iter. 102/499: loss=9.046552477133634, w0=66.33451999999996, w1=7.542759507922918\n",
      "SubGD iter. 103/499: loss=8.704760514732394, w0=66.71139999999995, w1=7.846017516367622\n",
      "SubGD iter. 104/499: loss=8.372871671628248, w0=67.07791999999995, w1=8.14916807677339\n",
      "SubGD iter. 105/499: loss=8.052713872262576, w0=67.43603999999995, w1=8.450471378640438\n",
      "SubGD iter. 106/499: loss=7.741845358498797, w0=67.78645999999995, w1=8.751045452661135\n",
      "SubGD iter. 107/499: loss=7.44063649784793, w0=68.12511999999995, w1=9.049215722252919\n",
      "SubGD iter. 108/499: loss=7.152144892432363, w0=68.45537999999995, w1=9.343976087699675\n",
      "SubGD iter. 109/499: loss=6.874953545674687, w0=68.77695999999995, w1=9.63509237267304\n",
      "SubGD iter. 110/499: loss=6.609759691657238, w0=69.08803999999995, w1=9.9194932820734\n",
      "SubGD iter. 111/499: loss=6.35966446534739, w0=69.38749999999995, w1=10.197623582279036\n",
      "SubGD iter. 112/499: loss=6.125559830337072, w0=69.67281999999994, w1=10.468063593613422\n",
      "SubGD iter. 113/499: loss=5.908756851126092, w0=69.94651999999995, w1=10.728826346302036\n",
      "SubGD iter. 114/499: loss=5.708346277966657, w0=70.20887999999995, w1=10.979299692022309\n",
      "SubGD iter. 115/499: loss=5.524903595719336, w0=70.45653999999995, w1=11.220392679253402\n",
      "SubGD iter. 116/499: loss=5.358572110476767, w0=70.69215999999994, w1=11.44906635201675\n",
      "SubGD iter. 117/499: loss=5.208366578733316, w0=70.91545999999994, w1=11.664512641643435\n",
      "SubGD iter. 118/499: loss=5.075452050918027, w0=71.12447999999993, w1=11.864387168308966\n",
      "SubGD iter. 119/499: loss=4.9608399148823965, w0=71.31865999999994, w1=12.045105403559505\n",
      "SubGD iter. 120/499: loss=4.864240181709677, w0=71.49939999999994, w1=12.209836073165999\n",
      "SubGD iter. 121/499: loss=4.782724768945258, w0=71.66543999999993, w1=12.35747652189874\n",
      "SubGD iter. 122/499: loss=4.715208074668132, w0=71.81593999999993, w1=12.489808881940307\n",
      "SubGD iter. 123/499: loss=4.66014606377425, w0=71.95369999999993, w1=12.612418157319317\n",
      "SubGD iter. 124/499: loss=4.613848453064218, w0=72.08067999999993, w1=12.721366944472166\n",
      "SubGD iter. 125/499: loss=4.576038370591761, w0=72.19435999999993, w1=12.815458765817631\n",
      "SubGD iter. 126/499: loss=4.546649851049039, w0=72.29697999999993, w1=12.900592769395358\n",
      "SubGD iter. 127/499: loss=4.522563544988971, w0=72.38965999999994, w1=12.975769654279938\n",
      "SubGD iter. 128/499: loss=4.503077398110057, w0=72.47435999999993, w1=13.043963349302288\n",
      "SubGD iter. 129/499: loss=4.487012427842283, w0=72.55093999999994, w1=13.103277584601706\n",
      "SubGD iter. 130/499: loss=4.474309393425118, w0=72.62051999999994, w1=13.156032035188161\n",
      "SubGD iter. 131/499: loss=4.464166669156604, w0=72.68239999999994, w1=13.201870566969179\n",
      "SubGD iter. 132/499: loss=4.456202124936146, w0=72.73769999999995, w1=13.241365939188713\n",
      "SubGD iter. 133/499: loss=4.4499138373012075, w0=72.78823999999994, w1=13.276636749385766\n",
      "SubGD iter. 134/499: loss=4.444739448232768, w0=72.83401999999994, w1=13.308112586749704\n",
      "SubGD iter. 135/499: loss=4.440577063150133, w0=72.87447999999993, w1=13.335151520405024\n",
      "SubGD iter. 136/499: loss=4.4373967610583085, w0=72.91115999999994, w1=13.358430829065476\n",
      "SubGD iter. 137/499: loss=4.4348465287075, w0=72.94447999999994, w1=13.37925678085128\n",
      "SubGD iter. 138/499: loss=4.432811551436952, w0=72.97401999999994, w1=13.396406376905562\n",
      "SubGD iter. 139/499: loss=4.431233661858321, w0=73.00103999999993, w1=13.412189120459388\n",
      "SubGD iter. 140/499: loss=4.429913776135237, w0=73.02483999999993, w1=13.425274895313102\n",
      "SubGD iter. 141/499: loss=4.428916084676415, w0=73.04625999999993, w1=13.43622202132232\n",
      "SubGD iter. 142/499: loss=4.42811221458972, w0=73.06613999999993, w1=13.44744004660127\n",
      "SubGD iter. 143/499: loss=4.427409042227933, w0=73.08405999999994, w1=13.457856669597911\n",
      "SubGD iter. 144/499: loss=4.426825784996949, w0=73.10029999999993, w1=13.46733516273489\n",
      "SubGD iter. 145/499: loss=4.426369603365169, w0=73.11401999999994, w1=13.47539362822024\n",
      "SubGD iter. 146/499: loss=4.426030178383453, w0=73.12619999999994, w1=13.48221286443791\n",
      "SubGD iter. 147/499: loss=4.425766799370374, w0=73.13697999999994, w1=13.487997256911477\n",
      "SubGD iter. 148/499: loss=4.425555929007912, w0=73.14747999999993, w1=13.49347943914027\n",
      "SubGD iter. 149/499: loss=4.425362490640805, w0=73.15699999999993, w1=13.498468271254382\n",
      "SubGD iter. 150/499: loss=4.425203617363585, w0=73.16595999999993, w1=13.502946804297148\n",
      "SubGD iter. 151/499: loss=4.4250685279472615, w0=73.17365999999993, w1=13.50657602923627\n",
      "SubGD iter. 152/499: loss=4.424972782434855, w0=73.18009999999992, w1=13.509768665455125\n",
      "SubGD iter. 153/499: loss=4.424903121175712, w0=73.18597999999993, w1=13.512571468366602\n",
      "SubGD iter. 154/499: loss=4.424846327975847, w0=73.19143999999993, w1=13.515117410468873\n",
      "SubGD iter. 155/499: loss=4.42479923253376, w0=73.19605999999993, w1=13.517185961787703\n",
      "SubGD iter. 156/499: loss=4.4247664094040005, w0=73.19969999999994, w1=13.5180699308743\n",
      "SubGD iter. 157/499: loss=4.424747663519319, w0=73.20291999999993, w1=13.51885413776703\n",
      "SubGD iter. 158/499: loss=4.424732182668888, w0=73.20599999999993, w1=13.519529839268888\n",
      "SubGD iter. 159/499: loss=4.424717978422431, w0=73.20907999999993, w1=13.520205540770744\n",
      "SubGD iter. 160/499: loss=4.424704053977274, w0=73.21201999999992, w1=13.521000216270533\n",
      "SubGD iter. 161/499: loss=4.4246908038213455, w0=73.21495999999992, w1=13.521794891770321\n",
      "SubGD iter. 162/499: loss=4.424678207991665, w0=73.21747999999992, w1=13.52240720954696\n",
      "SubGD iter. 163/499: loss=4.424668911605651, w0=73.21985999999993, w1=13.522732908460904\n",
      "SubGD iter. 164/499: loss=4.424660947850395, w0=73.22181999999992, w1=13.522991164028754\n",
      "SubGD iter. 165/499: loss=4.424655537307837, w0=73.22363999999992, w1=13.523086524955826\n",
      "SubGD iter. 166/499: loss=4.424651183353665, w0=73.22503999999992, w1=13.522757010157413\n",
      "SubGD iter. 167/499: loss=4.424648228239375, w0=73.22643999999993, w1=13.522427495359\n",
      "SubGD iter. 168/499: loss=4.424645273125086, w0=73.22783999999993, w1=13.522097980560588\n",
      "SubGD iter. 169/499: loss=4.424642498283795, w0=73.22895999999993, w1=13.52222596314126\n",
      "SubGD iter. 170/499: loss=4.424640682884452, w0=73.23007999999993, w1=13.522353945721932\n",
      "SubGD iter. 171/499: loss=4.424638867485107, w0=73.23119999999993, w1=13.522481928302604\n",
      "SubGD iter. 172/499: loss=4.4246373008521855, w0=73.23189999999992, w1=13.523013495747039\n",
      "SubGD iter. 173/499: loss=4.424636258655273, w0=73.23273999999992, w1=13.523266279565808\n",
      "SubGD iter. 174/499: loss=4.42463533941246, w0=73.23329999999991, w1=13.523741235074784\n",
      "SubGD iter. 175/499: loss=4.424634640448436, w0=73.23399999999991, w1=13.523937406958094\n",
      "SubGD iter. 176/499: loss=4.424633962890472, w0=73.2345599999999, w1=13.52388860470771\n",
      "SubGD iter. 177/499: loss=4.424633633499305, w0=73.23497999999991, w1=13.52411858608299\n",
      "SubGD iter. 178/499: loss=4.424633305940115, w0=73.23539999999991, w1=13.52434856745827\n",
      "SubGD iter. 179/499: loss=4.424632978380925, w0=73.23581999999992, w1=13.524578548833551\n",
      "SubGD iter. 180/499: loss=4.424632650821734, w0=73.23623999999992, w1=13.524808530208832\n",
      "SubGD iter. 181/499: loss=4.424632389924093, w0=73.23651999999993, w1=13.524964267899282\n",
      "SubGD iter. 182/499: loss=4.424632243275195, w0=73.23679999999993, w1=13.525120005589732\n",
      "SubGD iter. 183/499: loss=4.424632096626298, w0=73.23707999999993, w1=13.525275743280183\n",
      "SubGD iter. 184/499: loss=4.424631993328701, w0=73.23721999999994, w1=13.525174424196214\n",
      "SubGD iter. 185/499: loss=4.42463195066362, w0=73.23735999999994, w1=13.525073105112245\n",
      "SubGD iter. 186/499: loss=4.424631907998538, w0=73.23749999999994, w1=13.524971786028276\n",
      "SubGD iter. 187/499: loss=4.424631865333457, w0=73.23763999999994, w1=13.524870466944307\n",
      "SubGD iter. 188/499: loss=4.424631822668376, w0=73.23777999999994, w1=13.524769147860338\n",
      "SubGD iter. 189/499: loss=4.424631782685974, w0=73.23805999999995, w1=13.524924885550789\n",
      "SubGD iter. 190/499: loss=4.42463174654501, w0=73.23819999999995, w1=13.52482356646682\n",
      "SubGD iter. 191/499: loss=4.424631703879928, w0=73.23833999999995, w1=13.52472224738285\n",
      "SubGD iter. 192/499: loss=4.424631661214847, w0=73.23847999999995, w1=13.524620928298882\n",
      "SubGD iter. 193/499: loss=4.424631622214843, w0=73.23847999999995, w1=13.524586781150326\n",
      "SubGD iter. 194/499: loss=4.424631620549089, w0=73.23847999999995, w1=13.52455263400177\n",
      "SubGD iter. 195/499: loss=4.424631618883335, w0=73.23847999999995, w1=13.524518486853214\n",
      "SubGD iter. 196/499: loss=4.424631617217582, w0=73.23847999999995, w1=13.524484339704658\n",
      "SubGD iter. 197/499: loss=4.424631615551827, w0=73.23847999999995, w1=13.524450192556102\n",
      "SubGD iter. 198/499: loss=4.424631613886074, w0=73.23847999999995, w1=13.524416045407547\n",
      "SubGD iter. 199/499: loss=4.4246316122203195, w0=73.23847999999995, w1=13.52438189825899\n",
      "SubGD iter. 200/499: loss=4.424631615444578, w0=73.23861999999995, w1=13.524604807884854\n",
      "SubGD iter. 201/499: loss=4.424631621428463, w0=73.23861999999995, w1=13.524570660736298\n",
      "SubGD iter. 202/499: loss=4.424631619762709, w0=73.23861999999995, w1=13.524536513587742\n",
      "SubGD iter. 203/499: loss=4.424631618096955, w0=73.23861999999995, w1=13.524502366439187\n",
      "SubGD iter. 204/499: loss=4.424631616431201, w0=73.23861999999995, w1=13.52446821929063\n",
      "SubGD iter. 205/499: loss=4.424631614765447, w0=73.23861999999995, w1=13.524434072142075\n",
      "SubGD iter. 206/499: loss=4.4246316130996926, w0=73.23861999999995, w1=13.524399924993519\n",
      "SubGD iter. 207/499: loss=4.42463161143394, w0=73.23861999999995, w1=13.524365777844963\n",
      "SubGD iter. 208/499: loss=4.424631609768185, w0=73.23861999999995, w1=13.524331630696407\n",
      "SubGD iter. 209/499: loss=4.42463160810243, w0=73.23861999999995, w1=13.524297483547851\n",
      "SubGD iter. 210/499: loss=4.4246316143257935, w0=73.23875999999996, w1=13.524520393173715\n",
      "SubGD iter. 211/499: loss=4.424631617310575, w0=73.23875999999996, w1=13.524486246025159\n",
      "SubGD iter. 212/499: loss=4.424631615644821, w0=73.23875999999996, w1=13.524452098876603\n",
      "SubGD iter. 213/499: loss=4.4246316139790665, w0=73.23875999999996, w1=13.524417951728047\n",
      "SubGD iter. 214/499: loss=4.424631612313314, w0=73.23875999999996, w1=13.524383804579491\n",
      "SubGD iter. 215/499: loss=4.424631610647559, w0=73.23875999999996, w1=13.524349657430935\n",
      "SubGD iter. 216/499: loss=4.424631608981804, w0=73.23875999999996, w1=13.52431551028238\n",
      "SubGD iter. 217/499: loss=4.424631607316051, w0=73.23875999999996, w1=13.524281363133824\n",
      "SubGD iter. 218/499: loss=4.424631605650297, w0=73.23875999999996, w1=13.524247215985268\n",
      "SubGD iter. 219/499: loss=4.424631603984544, w0=73.23875999999996, w1=13.524213068836712\n",
      "SubGD iter. 220/499: loss=4.42463161320701, w0=73.23889999999996, w1=13.524435978462575\n",
      "SubGD iter. 221/499: loss=4.424631613192687, w0=73.23889999999996, w1=13.52440183131402\n",
      "SubGD iter. 222/499: loss=4.424631611526932, w0=73.23889999999996, w1=13.524367684165464\n",
      "SubGD iter. 223/499: loss=4.424631609861179, w0=73.23889999999996, w1=13.524333537016908\n",
      "SubGD iter. 224/499: loss=4.4246316081954244, w0=73.23889999999996, w1=13.524299389868352\n",
      "SubGD iter. 225/499: loss=4.424631606529671, w0=73.23889999999996, w1=13.524265242719796\n",
      "SubGD iter. 226/499: loss=4.424631604863916, w0=73.23889999999996, w1=13.52423109557124\n",
      "SubGD iter. 227/499: loss=4.424631603198163, w0=73.23889999999996, w1=13.524196948422684\n",
      "SubGD iter. 228/499: loss=4.4246316015324085, w0=73.23889999999996, w1=13.524162801274128\n",
      "SubGD iter. 229/499: loss=4.4246316012143305, w0=73.23903999999996, w1=13.524385710899992\n",
      "SubGD iter. 230/499: loss=4.424631610740553, w0=73.23903999999996, w1=13.524351563751436\n",
      "SubGD iter. 231/499: loss=4.424631609074798, w0=73.23903999999996, w1=13.52431741660288\n",
      "SubGD iter. 232/499: loss=4.424631607409045, w0=73.23903999999996, w1=13.524283269454324\n",
      "SubGD iter. 233/499: loss=4.424631605743291, w0=73.23903999999996, w1=13.524249122305768\n",
      "SubGD iter. 234/499: loss=4.424631604077536, w0=73.23903999999996, w1=13.524214975157212\n",
      "SubGD iter. 235/499: loss=4.4246316024117816, w0=73.23903999999996, w1=13.524180828008657\n",
      "SubGD iter. 236/499: loss=4.42463160074603, w0=73.23903999999996, w1=13.5241466808601\n",
      "SubGD iter. 237/499: loss=4.424631599080274, w0=73.23903999999996, w1=13.524112533711545\n",
      "SubGD iter. 238/499: loss=4.424631597414521, w0=73.23903999999996, w1=13.524078386562989\n",
      "SubGD iter. 239/499: loss=4.424631600095546, w0=73.23917999999996, w1=13.524301296188852\n",
      "SubGD iter. 240/499: loss=4.424631606622665, w0=73.23917999999996, w1=13.524267149040297\n",
      "SubGD iter. 241/499: loss=4.42463160495691, w0=73.23917999999996, w1=13.52423300189174\n",
      "SubGD iter. 242/499: loss=4.424631603291157, w0=73.23917999999996, w1=13.524198854743185\n",
      "SubGD iter. 243/499: loss=4.424631601625403, w0=73.23917999999996, w1=13.524164707594629\n",
      "SubGD iter. 244/499: loss=4.42463159995965, w0=73.23917999999996, w1=13.524130560446073\n",
      "SubGD iter. 245/499: loss=4.424631598293894, w0=73.23917999999996, w1=13.524096413297517\n",
      "SubGD iter. 246/499: loss=4.42463159662814, w0=73.23917999999996, w1=13.524062266148961\n",
      "SubGD iter. 247/499: loss=4.424631594962387, w0=73.23917999999996, w1=13.524028119000405\n",
      "SubGD iter. 248/499: loss=4.424631593296633, w0=73.23917999999996, w1=13.52399397185185\n",
      "SubGD iter. 249/499: loss=4.424631598976763, w0=73.23931999999996, w1=13.524216881477713\n",
      "SubGD iter. 250/499: loss=4.424631602504776, w0=73.23931999999996, w1=13.524182734329157\n",
      "SubGD iter. 251/499: loss=4.424631600839022, w0=73.23931999999996, w1=13.524148587180601\n",
      "SubGD iter. 252/499: loss=4.424631599173268, w0=73.23931999999996, w1=13.524114440032045\n",
      "SubGD iter. 253/499: loss=4.4246315975075134, w0=73.23931999999996, w1=13.52408029288349\n",
      "SubGD iter. 254/499: loss=4.424631595841761, w0=73.23931999999996, w1=13.524046145734934\n",
      "SubGD iter. 255/499: loss=4.424631594176007, w0=73.23931999999996, w1=13.524011998586378\n",
      "SubGD iter. 256/499: loss=4.424631592510252, w0=73.23931999999996, w1=13.523977851437822\n",
      "SubGD iter. 257/499: loss=4.424631590844498, w0=73.23931999999996, w1=13.523943704289266\n",
      "SubGD iter. 258/499: loss=4.424631589178745, w0=73.23931999999996, w1=13.52390955714071\n",
      "SubGD iter. 259/499: loss=4.42463159785798, w0=73.23945999999997, w1=13.524132466766574\n",
      "SubGD iter. 260/499: loss=4.424631598386887, w0=73.23945999999997, w1=13.524098319618018\n",
      "SubGD iter. 261/499: loss=4.4246315967211345, w0=73.23945999999997, w1=13.524064172469462\n",
      "SubGD iter. 262/499: loss=4.42463159505538, w0=73.23945999999997, w1=13.524030025320906\n",
      "SubGD iter. 263/499: loss=4.424631593389626, w0=73.23945999999997, w1=13.52399587817235\n",
      "SubGD iter. 264/499: loss=4.424631591723872, w0=73.23945999999997, w1=13.523961731023794\n",
      "SubGD iter. 265/499: loss=4.424631590058119, w0=73.23945999999997, w1=13.523927583875238\n",
      "SubGD iter. 266/499: loss=4.424631588392364, w0=73.23945999999997, w1=13.523893436726683\n",
      "SubGD iter. 267/499: loss=4.424631586726611, w0=73.23945999999997, w1=13.523859289578127\n",
      "SubGD iter. 268/499: loss=4.424631585865299, w0=73.23959999999997, w1=13.52408219920399\n",
      "SubGD iter. 269/499: loss=4.424631595934754, w0=73.23959999999997, w1=13.524048052055434\n",
      "SubGD iter. 270/499: loss=4.424631594268999, w0=73.23959999999997, w1=13.524013904906878\n",
      "SubGD iter. 271/499: loss=4.424631592603246, w0=73.23959999999997, w1=13.523979757758323\n",
      "SubGD iter. 272/499: loss=4.424631590937492, w0=73.23959999999997, w1=13.523945610609767\n",
      "SubGD iter. 273/499: loss=4.424631589271738, w0=73.23959999999997, w1=13.52391146346121\n",
      "SubGD iter. 274/499: loss=4.424631587605984, w0=73.23959999999997, w1=13.523877316312655\n",
      "SubGD iter. 275/499: loss=4.424631585940229, w0=73.23959999999997, w1=13.523843169164099\n",
      "SubGD iter. 276/499: loss=4.424631584274477, w0=73.23959999999997, w1=13.523809022015543\n",
      "SubGD iter. 277/499: loss=4.424631582608722, w0=73.23959999999997, w1=13.523774874866987\n",
      "SubGD iter. 278/499: loss=4.424631584746516, w0=73.23973999999997, w1=13.52399778449285\n",
      "SubGD iter. 279/499: loss=4.424631591816865, w0=73.23973999999997, w1=13.523963637344295\n",
      "SubGD iter. 280/499: loss=4.424631590151113, w0=73.23973999999997, w1=13.523929490195739\n",
      "SubGD iter. 281/499: loss=4.424631588485357, w0=73.23973999999997, w1=13.523895343047183\n",
      "SubGD iter. 282/499: loss=4.424631586819604, w0=73.23973999999997, w1=13.523861195898627\n",
      "SubGD iter. 283/499: loss=4.4246315851538505, w0=73.23973999999997, w1=13.523827048750071\n",
      "SubGD iter. 284/499: loss=4.424631583488096, w0=73.23973999999997, w1=13.523792901601515\n",
      "SubGD iter. 285/499: loss=4.424631581822342, w0=73.23973999999997, w1=13.52375875445296\n",
      "SubGD iter. 286/499: loss=4.424631580156588, w0=73.23973999999997, w1=13.523724607304404\n",
      "SubGD iter. 287/499: loss=4.424631578490834, w0=73.23973999999997, w1=13.523690460155848\n",
      "SubGD iter. 288/499: loss=4.424631583627733, w0=73.23987999999997, w1=13.523913369781711\n",
      "SubGD iter. 289/499: loss=4.424631587698977, w0=73.23987999999997, w1=13.523879222633155\n",
      "SubGD iter. 290/499: loss=4.4246315860332235, w0=73.23987999999997, w1=13.5238450754846\n",
      "SubGD iter. 291/499: loss=4.42463158436747, w0=73.23987999999997, w1=13.523810928336044\n",
      "SubGD iter. 292/499: loss=4.424631582701715, w0=73.23987999999997, w1=13.523776781187488\n",
      "SubGD iter. 293/499: loss=4.424631581035961, w0=73.23987999999997, w1=13.523742634038932\n",
      "SubGD iter. 294/499: loss=4.424631579370208, w0=73.23987999999997, w1=13.523708486890376\n",
      "SubGD iter. 295/499: loss=4.424631577704454, w0=73.23987999999997, w1=13.52367433974182\n",
      "SubGD iter. 296/499: loss=4.4246315760387, w0=73.23987999999997, w1=13.523640192593264\n",
      "SubGD iter. 297/499: loss=4.424631574372945, w0=73.23987999999997, w1=13.523606045444708\n",
      "SubGD iter. 298/499: loss=4.424631582508949, w0=73.24001999999997, w1=13.523828955070572\n",
      "SubGD iter. 299/499: loss=4.42463158358109, w0=73.24001999999997, w1=13.523794807922016\n",
      "SubGD iter. 300/499: loss=4.424631581915335, w0=73.24001999999997, w1=13.52376066077346\n",
      "SubGD iter. 301/499: loss=4.4246315802495815, w0=73.24001999999997, w1=13.523726513624904\n",
      "SubGD iter. 302/499: loss=4.424631578583828, w0=73.24001999999997, w1=13.523692366476348\n",
      "SubGD iter. 303/499: loss=4.424631576918073, w0=73.24001999999997, w1=13.523658219327793\n",
      "SubGD iter. 304/499: loss=4.42463157525232, w0=73.24001999999997, w1=13.523624072179237\n",
      "SubGD iter. 305/499: loss=4.4246315735865664, w0=73.24001999999997, w1=13.52358992503068\n",
      "SubGD iter. 306/499: loss=4.424631571920811, w0=73.24001999999997, w1=13.523555777882125\n",
      "SubGD iter. 307/499: loss=4.4246315705162695, w0=73.24015999999997, w1=13.523778687507988\n",
      "SubGD iter. 308/499: loss=4.424631581128956, w0=73.24015999999997, w1=13.523744540359433\n",
      "SubGD iter. 309/499: loss=4.424631579463202, w0=73.24015999999997, w1=13.523710393210877\n",
      "SubGD iter. 310/499: loss=4.424631577797446, w0=73.24015999999997, w1=13.52367624606232\n",
      "SubGD iter. 311/499: loss=4.424631576131694, w0=73.24015999999997, w1=13.523642098913765\n",
      "SubGD iter. 312/499: loss=4.4246315744659395, w0=73.24015999999997, w1=13.523607951765209\n",
      "SubGD iter. 313/499: loss=4.424631572800186, w0=73.24015999999997, w1=13.523573804616653\n",
      "SubGD iter. 314/499: loss=4.424631571134432, w0=73.24015999999997, w1=13.523539657468097\n",
      "SubGD iter. 315/499: loss=4.424631569468677, w0=73.24015999999997, w1=13.523505510319541\n",
      "SubGD iter. 316/499: loss=4.424631567802924, w0=73.24015999999997, w1=13.523471363170986\n",
      "SubGD iter. 317/499: loss=4.424631569397486, w0=73.24029999999998, w1=13.523694272796849\n",
      "SubGD iter. 318/499: loss=4.424631577011067, w0=73.24029999999998, w1=13.523660125648293\n",
      "SubGD iter. 319/499: loss=4.424631575345313, w0=73.24029999999998, w1=13.523625978499737\n",
      "SubGD iter. 320/499: loss=4.4246315736795605, w0=73.24029999999998, w1=13.523591831351181\n",
      "SubGD iter. 321/499: loss=4.424631572013805, w0=73.24029999999998, w1=13.523557684202625\n",
      "SubGD iter. 322/499: loss=4.424631570348052, w0=73.24029999999998, w1=13.52352353705407\n",
      "SubGD iter. 323/499: loss=4.4246315686822975, w0=73.24029999999998, w1=13.523489389905514\n",
      "SubGD iter. 324/499: loss=4.424631567016544, w0=73.24029999999998, w1=13.523455242756958\n",
      "SubGD iter. 325/499: loss=4.42463156535079, w0=73.24029999999998, w1=13.523421095608402\n",
      "SubGD iter. 326/499: loss=4.424631563685035, w0=73.24029999999998, w1=13.523386948459846\n",
      "SubGD iter. 327/499: loss=4.424631568278702, w0=73.24043999999998, w1=13.52360985808571\n",
      "SubGD iter. 328/499: loss=4.424631572893179, w0=73.24043999999998, w1=13.523575710937154\n",
      "SubGD iter. 329/499: loss=4.424631571227425, w0=73.24043999999998, w1=13.523541563788598\n",
      "SubGD iter. 330/499: loss=4.424631569561671, w0=73.24043999999998, w1=13.523507416640042\n",
      "SubGD iter. 331/499: loss=4.424631567895917, w0=73.24043999999998, w1=13.523473269491486\n",
      "SubGD iter. 332/499: loss=4.424631566230164, w0=73.24043999999998, w1=13.52343912234293\n",
      "SubGD iter. 333/499: loss=4.424631564564409, w0=73.24043999999998, w1=13.523404975194374\n",
      "SubGD iter. 334/499: loss=4.4246315628986554, w0=73.24043999999998, w1=13.523370828045818\n",
      "SubGD iter. 335/499: loss=4.424631561232902, w0=73.24043999999998, w1=13.523336680897263\n",
      "SubGD iter. 336/499: loss=4.424631559567148, w0=73.24043999999998, w1=13.523302533748707\n",
      "SubGD iter. 337/499: loss=4.42463156715992, w0=73.24057999999998, w1=13.52352544337457\n",
      "SubGD iter. 338/499: loss=4.4246315687752915, w0=73.24057999999998, w1=13.523491296226014\n",
      "SubGD iter. 339/499: loss=4.424631567109538, w0=73.24057999999998, w1=13.523457149077458\n",
      "SubGD iter. 340/499: loss=4.424631565443783, w0=73.24057999999998, w1=13.523423001928903\n",
      "SubGD iter. 341/499: loss=4.424631563778029, w0=73.24057999999998, w1=13.523388854780347\n",
      "SubGD iter. 342/499: loss=4.424631562112276, w0=73.24057999999998, w1=13.52335470763179\n",
      "SubGD iter. 343/499: loss=4.424631560446521, w0=73.24057999999998, w1=13.523320560483235\n",
      "SubGD iter. 344/499: loss=4.424631558780768, w0=73.24057999999998, w1=13.523286413334679\n",
      "SubGD iter. 345/499: loss=4.424631557115013, w0=73.24057999999998, w1=13.523252266186123\n",
      "SubGD iter. 346/499: loss=4.42463155544926, w0=73.24057999999998, w1=13.523218119037567\n",
      "SubGD iter. 347/499: loss=4.4246315660411355, w0=73.24071999999998, w1=13.52344102866343\n",
      "SubGD iter. 348/499: loss=4.424631564657403, w0=73.24071999999998, w1=13.523406881514875\n",
      "SubGD iter. 349/499: loss=4.4246315629916495, w0=73.24071999999998, w1=13.523372734366319\n",
      "SubGD iter. 350/499: loss=4.424631561325895, w0=73.24071999999998, w1=13.523338587217763\n",
      "SubGD iter. 351/499: loss=4.424631559660141, w0=73.24071999999998, w1=13.523304440069207\n",
      "SubGD iter. 352/499: loss=4.4246315579943865, w0=73.24071999999998, w1=13.523270292920651\n",
      "SubGD iter. 353/499: loss=4.424631556328634, w0=73.24071999999998, w1=13.523236145772096\n",
      "SubGD iter. 354/499: loss=4.424631554662879, w0=73.24071999999998, w1=13.52320199862354\n",
      "SubGD iter. 355/499: loss=4.424631552997125, w0=73.24071999999998, w1=13.523167851474984\n",
      "SubGD iter. 356/499: loss=4.424631554048455, w0=73.24085999999998, w1=13.523390761100847\n",
      "SubGD iter. 357/499: loss=4.424631562205269, w0=73.24085999999998, w1=13.523356613952291\n",
      "SubGD iter. 358/499: loss=4.424631560539515, w0=73.24085999999998, w1=13.523322466803736\n",
      "SubGD iter. 359/499: loss=4.42463155887376, w0=73.24085999999998, w1=13.52328831965518\n",
      "SubGD iter. 360/499: loss=4.4246315572080075, w0=73.24085999999998, w1=13.523254172506624\n",
      "SubGD iter. 361/499: loss=4.424631555542253, w0=73.24085999999998, w1=13.523220025358068\n",
      "SubGD iter. 362/499: loss=4.424631553876498, w0=73.24085999999998, w1=13.523185878209512\n",
      "SubGD iter. 363/499: loss=4.4246315522107444, w0=73.24085999999998, w1=13.523151731060956\n",
      "SubGD iter. 364/499: loss=4.424631550544991, w0=73.24085999999998, w1=13.5231175839124\n",
      "SubGD iter. 365/499: loss=4.424631548879237, w0=73.24085999999998, w1=13.523083436763844\n",
      "SubGD iter. 366/499: loss=4.424631552929672, w0=73.24099999999999, w1=13.523306346389708\n",
      "SubGD iter. 367/499: loss=4.4246315580873805, w0=73.24099999999999, w1=13.523272199241152\n",
      "SubGD iter. 368/499: loss=4.424631556421627, w0=73.24099999999999, w1=13.523238052092596\n",
      "SubGD iter. 369/499: loss=4.424631554755872, w0=73.24099999999999, w1=13.52320390494404\n",
      "SubGD iter. 370/499: loss=4.424631553090119, w0=73.24099999999999, w1=13.523169757795484\n",
      "SubGD iter. 371/499: loss=4.424631551424365, w0=73.24099999999999, w1=13.523135610646928\n",
      "SubGD iter. 372/499: loss=4.424631549758611, w0=73.24099999999999, w1=13.523101463498373\n",
      "SubGD iter. 373/499: loss=4.424631548092857, w0=73.24099999999999, w1=13.523067316349817\n",
      "SubGD iter. 374/499: loss=4.424631546427102, w0=73.24099999999999, w1=13.52303316920126\n",
      "SubGD iter. 375/499: loss=4.42463154476135, w0=73.24099999999999, w1=13.522999022052705\n",
      "SubGD iter. 376/499: loss=4.424631551810888, w0=73.24113999999999, w1=13.523221931678568\n",
      "SubGD iter. 377/499: loss=4.424631553969492, w0=73.24113999999999, w1=13.523187784530013\n",
      "SubGD iter. 378/499: loss=4.4246315523037385, w0=73.24113999999999, w1=13.523153637381457\n",
      "SubGD iter. 379/499: loss=4.424631550637985, w0=73.24113999999999, w1=13.5231194902329\n",
      "SubGD iter. 380/499: loss=4.424631548972231, w0=73.24113999999999, w1=13.523085343084345\n",
      "SubGD iter. 381/499: loss=4.424631547306478, w0=73.24113999999999, w1=13.523051195935789\n",
      "SubGD iter. 382/499: loss=4.4246315456407235, w0=73.24113999999999, w1=13.523017048787233\n",
      "SubGD iter. 383/499: loss=4.424631543974968, w0=73.24113999999999, w1=13.522982901638677\n",
      "SubGD iter. 384/499: loss=4.424631542309214, w0=73.24113999999999, w1=13.522948754490121\n",
      "SubGD iter. 385/499: loss=4.424631540643461, w0=73.24113999999999, w1=13.522914607341566\n",
      "SubGD iter. 386/499: loss=4.424631550692105, w0=73.24127999999999, w1=13.523137516967429\n",
      "SubGD iter. 387/499: loss=4.424631549851604, w0=73.24127999999999, w1=13.523103369818873\n",
      "SubGD iter. 388/499: loss=4.42463154818585, w0=73.24127999999999, w1=13.523069222670317\n",
      "SubGD iter. 389/499: loss=4.4246315465200965, w0=73.24127999999999, w1=13.523035075521761\n",
      "SubGD iter. 390/499: loss=4.424631544854342, w0=73.24127999999999, w1=13.523000928373206\n",
      "SubGD iter. 391/499: loss=4.424631543188589, w0=73.24127999999999, w1=13.52296678122465\n",
      "SubGD iter. 392/499: loss=4.424631541522834, w0=73.24127999999999, w1=13.522932634076094\n",
      "SubGD iter. 393/499: loss=4.424631539857081, w0=73.24127999999999, w1=13.522898486927538\n",
      "SubGD iter. 394/499: loss=4.424631538191327, w0=73.24127999999999, w1=13.522864339778982\n",
      "SubGD iter. 395/499: loss=4.4246315386994235, w0=73.24141999999999, w1=13.523087249404846\n",
      "SubGD iter. 396/499: loss=4.4246315473994695, w0=73.24141999999999, w1=13.52305310225629\n",
      "SubGD iter. 397/499: loss=4.424631545733716, w0=73.24141999999999, w1=13.523018955107734\n",
      "SubGD iter. 398/499: loss=4.424631544067962, w0=73.24141999999999, w1=13.522984807959178\n",
      "SubGD iter. 399/499: loss=4.424631542402208, w0=73.24141999999999, w1=13.522950660810622\n",
      "SubGD iter. 400/499: loss=4.4246315407364545, w0=73.24141999999999, w1=13.522916513662066\n",
      "SubGD iter. 401/499: loss=4.424631539070701, w0=73.24141999999999, w1=13.52288236651351\n",
      "SubGD iter. 402/499: loss=4.424631537404946, w0=73.24141999999999, w1=13.522848219364954\n",
      "SubGD iter. 403/499: loss=4.424631535739193, w0=73.24141999999999, w1=13.522814072216399\n",
      "SubGD iter. 404/499: loss=4.424631534073439, w0=73.24141999999999, w1=13.522779925067843\n",
      "SubGD iter. 405/499: loss=4.424631537580641, w0=73.24155999999999, w1=13.523002834693706\n",
      "SubGD iter. 406/499: loss=4.424631543281581, w0=73.24155999999999, w1=13.52296868754515\n",
      "SubGD iter. 407/499: loss=4.424631541615828, w0=73.24155999999999, w1=13.522934540396594\n",
      "SubGD iter. 408/499: loss=4.424631539950075, w0=73.24155999999999, w1=13.522900393248038\n",
      "SubGD iter. 409/499: loss=4.42463153828432, w0=73.24155999999999, w1=13.522866246099483\n",
      "SubGD iter. 410/499: loss=4.424631536618566, w0=73.24155999999999, w1=13.522832098950927\n",
      "SubGD iter. 411/499: loss=4.4246315349528125, w0=73.24155999999999, w1=13.52279795180237\n",
      "SubGD iter. 412/499: loss=4.424631533287058, w0=73.24155999999999, w1=13.522763804653815\n",
      "SubGD iter. 413/499: loss=4.424631531621305, w0=73.24155999999999, w1=13.52272965750526\n",
      "SubGD iter. 414/499: loss=4.42463152995555, w0=73.24155999999999, w1=13.522695510356703\n",
      "SubGD iter. 415/499: loss=4.424631536461858, w0=73.2417, w1=13.522918419982567\n",
      "SubGD iter. 416/499: loss=4.4246315403358025, w0=73.24155999999999, w1=13.5229056306811\n",
      "SubGD iter. 417/499: loss=4.424631538539811, w0=73.24155999999999, w1=13.522871483532544\n",
      "SubGD iter. 418/499: loss=4.424631536874056, w0=73.24155999999999, w1=13.522837336383988\n",
      "SubGD iter. 419/499: loss=4.424631535208303, w0=73.24155999999999, w1=13.522803189235432\n",
      "SubGD iter. 420/499: loss=4.424631533542549, w0=73.24155999999999, w1=13.522769042086876\n",
      "SubGD iter. 421/499: loss=4.424631531876795, w0=73.24155999999999, w1=13.52273489493832\n",
      "SubGD iter. 422/499: loss=4.42463153021104, w0=73.24155999999999, w1=13.522700747789765\n",
      "SubGD iter. 423/499: loss=4.424631534794037, w0=73.2417, w1=13.522923657415628\n",
      "SubGD iter. 424/499: loss=4.424631540431494, w0=73.24155999999999, w1=13.522910868114161\n",
      "SubGD iter. 425/499: loss=4.4246315387953015, w0=73.24155999999999, w1=13.522876720965606\n",
      "SubGD iter. 426/499: loss=4.424631537129548, w0=73.24155999999999, w1=13.52284257381705\n",
      "SubGD iter. 427/499: loss=4.424631535463794, w0=73.24155999999999, w1=13.522808426668494\n",
      "SubGD iter. 428/499: loss=4.42463153379804, w0=73.24155999999999, w1=13.522774279519938\n",
      "SubGD iter. 429/499: loss=4.4246315321322855, w0=73.24155999999999, w1=13.522740132371382\n",
      "SubGD iter. 430/499: loss=4.424631530466532, w0=73.24155999999999, w1=13.522705985222826\n",
      "SubGD iter. 431/499: loss=4.424631533126217, w0=73.2417, w1=13.52292889484869\n",
      "SubGD iter. 432/499: loss=4.424631540527184, w0=73.24155999999999, w1=13.522916105547223\n",
      "SubGD iter. 433/499: loss=4.424631539050791, w0=73.24155999999999, w1=13.522881958398667\n",
      "SubGD iter. 434/499: loss=4.4246315373850384, w0=73.24155999999999, w1=13.522847811250111\n",
      "SubGD iter. 435/499: loss=4.424631535719284, w0=73.24155999999999, w1=13.522813664101555\n",
      "SubGD iter. 436/499: loss=4.424631534053529, w0=73.24155999999999, w1=13.522779516953\n",
      "SubGD iter. 437/499: loss=4.424631532387776, w0=73.24155999999999, w1=13.522745369804444\n",
      "SubGD iter. 438/499: loss=4.424631530722022, w0=73.24155999999999, w1=13.522711222655888\n",
      "SubGD iter. 439/499: loss=4.424631531458398, w0=73.2417, w1=13.522934132281751\n",
      "SubGD iter. 440/499: loss=4.424631540622873, w0=73.24155999999999, w1=13.522921342980284\n",
      "SubGD iter. 441/499: loss=4.424631539306283, w0=73.24155999999999, w1=13.522887195831728\n",
      "SubGD iter. 442/499: loss=4.424631537640528, w0=73.24155999999999, w1=13.522853048683173\n",
      "SubGD iter. 443/499: loss=4.424631535974775, w0=73.24155999999999, w1=13.522818901534617\n",
      "SubGD iter. 444/499: loss=4.42463153430902, w0=73.24155999999999, w1=13.52278475438606\n",
      "SubGD iter. 445/499: loss=4.424631532643267, w0=73.24155999999999, w1=13.522750607237505\n",
      "SubGD iter. 446/499: loss=4.424631530977512, w0=73.24155999999999, w1=13.52271646008895\n",
      "SubGD iter. 447/499: loss=4.4246315297905765, w0=73.2417, w1=13.522939369714813\n",
      "SubGD iter. 448/499: loss=4.424631540718564, w0=73.24155999999999, w1=13.522926580413346\n",
      "SubGD iter. 449/499: loss=4.424631539561774, w0=73.24155999999999, w1=13.52289243326479\n",
      "SubGD iter. 450/499: loss=4.424631537896019, w0=73.24155999999999, w1=13.522858286116234\n",
      "SubGD iter. 451/499: loss=4.424631536230265, w0=73.24155999999999, w1=13.522824138967678\n",
      "SubGD iter. 452/499: loss=4.4246315345645115, w0=73.24155999999999, w1=13.522789991819122\n",
      "SubGD iter. 453/499: loss=4.424631532898757, w0=73.24155999999999, w1=13.522755844670566\n",
      "SubGD iter. 454/499: loss=4.424631531233004, w0=73.24155999999999, w1=13.52272169752201\n",
      "SubGD iter. 455/499: loss=4.424631529567249, w0=73.24155999999999, w1=13.522687550373455\n",
      "SubGD iter. 456/499: loss=4.424631538996653, w0=73.2417, w1=13.522910459999318\n",
      "SubGD iter. 457/499: loss=4.424631540190371, w0=73.24155999999999, w1=13.522897670697851\n",
      "SubGD iter. 458/499: loss=4.42463153815151, w0=73.24155999999999, w1=13.522863523549296\n",
      "SubGD iter. 459/499: loss=4.424631536485756, w0=73.24155999999999, w1=13.52282937640074\n",
      "SubGD iter. 460/499: loss=4.424631534820002, w0=73.24155999999999, w1=13.522795229252184\n",
      "SubGD iter. 461/499: loss=4.424631533154248, w0=73.24155999999999, w1=13.522761082103628\n",
      "SubGD iter. 462/499: loss=4.424631531488494, w0=73.24155999999999, w1=13.522726934955072\n",
      "SubGD iter. 463/499: loss=4.42463152982274, w0=73.24155999999999, w1=13.522692787806516\n",
      "SubGD iter. 464/499: loss=4.424631537328833, w0=73.2417, w1=13.52291569743238\n",
      "SubGD iter. 465/499: loss=4.424631540286062, w0=73.24155999999999, w1=13.522902908130913\n",
      "SubGD iter. 466/499: loss=4.4246315384070005, w0=73.24155999999999, w1=13.522868760982357\n",
      "SubGD iter. 467/499: loss=4.424631536741246, w0=73.24155999999999, w1=13.522834613833801\n",
      "SubGD iter. 468/499: loss=4.424631535075491, w0=73.24155999999999, w1=13.522800466685245\n",
      "SubGD iter. 469/499: loss=4.424631533409738, w0=73.24155999999999, w1=13.52276631953669\n",
      "SubGD iter. 470/499: loss=4.424631531743984, w0=73.24155999999999, w1=13.522732172388134\n",
      "SubGD iter. 471/499: loss=4.424631530078232, w0=73.24155999999999, w1=13.522698025239578\n",
      "SubGD iter. 472/499: loss=4.424631535661012, w0=73.2417, w1=13.522920934865441\n",
      "SubGD iter. 473/499: loss=4.4246315403817515, w0=73.24155999999999, w1=13.522908145563974\n",
      "SubGD iter. 474/499: loss=4.42463153866249, w0=73.24155999999999, w1=13.522873998415418\n",
      "SubGD iter. 475/499: loss=4.4246315369967375, w0=73.24155999999999, w1=13.522839851266863\n",
      "SubGD iter. 476/499: loss=4.424631535330983, w0=73.24155999999999, w1=13.522805704118307\n",
      "SubGD iter. 477/499: loss=4.424631533665229, w0=73.24155999999999, w1=13.52277155696975\n",
      "SubGD iter. 478/499: loss=4.4246315319994745, w0=73.24155999999999, w1=13.522737409821195\n",
      "SubGD iter. 479/499: loss=4.424631530333721, w0=73.24155999999999, w1=13.52270326267264\n",
      "SubGD iter. 480/499: loss=4.424631533993192, w0=73.2417, w1=13.522926172298503\n",
      "SubGD iter. 481/499: loss=4.424631540477442, w0=73.24155999999999, w1=13.522913382997036\n",
      "SubGD iter. 482/499: loss=4.424631538917981, w0=73.24155999999999, w1=13.52287923584848\n",
      "SubGD iter. 483/499: loss=4.424631537252228, w0=73.24155999999999, w1=13.522845088699924\n",
      "SubGD iter. 484/499: loss=4.424631535586474, w0=73.24155999999999, w1=13.522810941551368\n",
      "SubGD iter. 485/499: loss=4.42463153392072, w0=73.24155999999999, w1=13.522776794402812\n",
      "SubGD iter. 486/499: loss=4.424631532254966, w0=73.24155999999999, w1=13.522742647254256\n",
      "SubGD iter. 487/499: loss=4.424631530589211, w0=73.24155999999999, w1=13.5227085001057\n",
      "SubGD iter. 488/499: loss=4.424631532325371, w0=73.2417, w1=13.522931409731564\n",
      "SubGD iter. 489/499: loss=4.424631540573132, w0=73.24155999999999, w1=13.522918620430097\n",
      "SubGD iter. 490/499: loss=4.424631539173472, w0=73.24155999999999, w1=13.522884473281541\n",
      "SubGD iter. 491/499: loss=4.424631537507718, w0=73.24155999999999, w1=13.522850326132986\n",
      "SubGD iter. 492/499: loss=4.4246315358419634, w0=73.24155999999999, w1=13.52281617898443\n",
      "SubGD iter. 493/499: loss=4.424631534176211, w0=73.24155999999999, w1=13.522782031835874\n",
      "SubGD iter. 494/499: loss=4.424631532510456, w0=73.24155999999999, w1=13.522747884687318\n",
      "SubGD iter. 495/499: loss=4.424631530844702, w0=73.24155999999999, w1=13.522713737538762\n",
      "SubGD iter. 496/499: loss=4.424631530657551, w0=73.2417, w1=13.522936647164626\n",
      "SubGD iter. 497/499: loss=4.424631540668822, w0=73.24155999999999, w1=13.522923857863159\n",
      "SubGD iter. 498/499: loss=4.424631539428963, w0=73.24155999999999, w1=13.522889710714603\n",
      "SubGD iter. 499/499: loss=4.424631537763208, w0=73.24155999999999, w1=13.522855563566047\n",
      "SubGD: execution time=0.093 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(\n",
    "    y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d3d97024f7416aad37882db435be5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses, subgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "            \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    batches = batch_iter(y, tx, batch_size, num_batches=max_iters, shuffle=True)\n",
    "    \n",
    "    for n_iter, (y_batch, tx_batch) in enumerate(batches):\n",
    "        loss = compute_mae_loss(y, tx, w)\n",
    "        grad = compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "        w = w - gamma * grad\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(\"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=73.29392200210518, w0=0.7, w1=0.2657809537774995\n",
      "SubSGD iter. 1/499: loss=72.59392200210519, w0=1.4, w1=0.4530513659164956\n",
      "SubSGD iter. 2/499: loss=71.89392200210516, w0=2.0999999999999996, w1=0.2987594452698628\n",
      "SubSGD iter. 3/499: loss=71.19392200210518, w0=2.8, w1=0.5093680539996013\n",
      "SubSGD iter. 4/499: loss=70.49392200210517, w0=3.5, w1=0.0018109248265282263\n",
      "SubSGD iter. 5/499: loss=69.79392200210518, w0=4.2, w1=-0.2340698146358525\n",
      "SubSGD iter. 6/499: loss=69.09392200210517, w0=4.9, w1=-0.6928439175025332\n",
      "SubSGD iter. 7/499: loss=68.39392200210516, w0=5.6000000000000005, w1=-0.29064348742586527\n",
      "SubSGD iter. 8/499: loss=67.69392200210517, w0=6.300000000000001, w1=-0.721530759691001\n",
      "SubSGD iter. 9/499: loss=66.99392200210518, w0=7.000000000000001, w1=0.4508208632108752\n",
      "SubSGD iter. 10/499: loss=66.29392200210518, w0=7.700000000000001, w1=1.6454802358067955\n",
      "SubSGD iter. 11/499: loss=65.59392200210517, w0=8.4, w1=1.535143339238126\n",
      "SubSGD iter. 12/499: loss=64.89392200210517, w0=9.1, w1=0.4869605708270168\n",
      "SubSGD iter. 13/499: loss=64.19392200210518, w0=9.799999999999999, w1=0.3890267740253257\n",
      "SubSGD iter. 14/499: loss=63.49392200210518, w0=10.499999999999998, w1=0.28941996168141404\n",
      "SubSGD iter. 15/499: loss=62.793922002105184, w0=11.199999999999998, w1=0.9244208359617022\n",
      "SubSGD iter. 16/499: loss=62.093922002105174, w0=11.899999999999997, w1=1.7471946810667864\n",
      "SubSGD iter. 17/499: loss=61.39392200210517, w0=12.599999999999996, w1=1.3834611096482878\n",
      "SubSGD iter. 18/499: loss=60.69392200210518, w0=13.299999999999995, w1=1.2799321042442373\n",
      "SubSGD iter. 19/499: loss=59.99392200210518, w0=13.999999999999995, w1=0.04077432369592837\n",
      "SubSGD iter. 20/499: loss=59.293922002105184, w0=14.699999999999994, w1=0.15019116336430632\n",
      "SubSGD iter. 21/499: loss=58.59392200210518, w0=15.399999999999993, w1=0.08737419901283651\n",
      "SubSGD iter. 22/499: loss=57.893922002105185, w0=16.099999999999994, w1=0.8706776067064059\n",
      "SubSGD iter. 23/499: loss=57.19392200210517, w0=16.799999999999994, w1=1.0346973321837376\n",
      "SubSGD iter. 24/499: loss=56.493922002105194, w0=17.499999999999993, w1=-0.01690877625923548\n",
      "SubSGD iter. 25/499: loss=55.793922002105184, w0=18.199999999999992, w1=0.23812852091113446\n",
      "SubSGD iter. 26/499: loss=55.09392200210518, w0=18.89999999999999, w1=-0.030719530835091158\n",
      "SubSGD iter. 27/499: loss=54.393922002105185, w0=19.59999999999999, w1=0.1968870212140819\n",
      "SubSGD iter. 28/499: loss=53.69392200210518, w0=20.29999999999999, w1=0.8715954646699489\n",
      "SubSGD iter. 29/499: loss=52.99392200210518, w0=20.99999999999999, w1=1.030377802758529\n",
      "SubSGD iter. 30/499: loss=52.293922002105184, w0=21.69999999999999, w1=0.8195582859733049\n",
      "SubSGD iter. 31/499: loss=51.59392200210519, w0=22.399999999999988, w1=0.9983088835604559\n",
      "SubSGD iter. 32/499: loss=50.893922002105185, w0=23.099999999999987, w1=1.162983846206578\n",
      "SubSGD iter. 33/499: loss=50.1939220021052, w0=23.799999999999986, w1=1.375579754077558\n",
      "SubSGD iter. 34/499: loss=49.49392200210519, w0=24.499999999999986, w1=1.311527936699952\n",
      "SubSGD iter. 35/499: loss=48.79392200210519, w0=25.199999999999985, w1=0.4488038852511238\n",
      "SubSGD iter. 36/499: loss=48.09392200210519, w0=25.899999999999984, w1=-0.9194118491567063\n",
      "SubSGD iter. 37/499: loss=47.393922002105185, w0=26.599999999999984, w1=-0.789193660685134\n",
      "SubSGD iter. 38/499: loss=46.6939220021052, w0=27.299999999999983, w1=0.3507855828961912\n",
      "SubSGD iter. 39/499: loss=45.993922002105194, w0=27.999999999999982, w1=0.7608480334832988\n",
      "SubSGD iter. 40/499: loss=45.29392200210519, w0=28.69999999999998, w1=1.09255471660333\n",
      "SubSGD iter. 41/499: loss=44.593922002105195, w0=29.39999999999998, w1=1.7070445806586436\n",
      "SubSGD iter. 42/499: loss=43.89392200210519, w0=30.09999999999998, w1=1.25041854799192\n",
      "SubSGD iter. 43/499: loss=43.1939220021052, w0=30.79999999999998, w1=0.7172997408124933\n",
      "SubSGD iter. 44/499: loss=42.493922002105194, w0=31.49999999999998, w1=1.1571534895739315\n",
      "SubSGD iter. 45/499: loss=41.79392200210519, w0=32.19999999999998, w1=0.9140306753389328\n",
      "SubSGD iter. 46/499: loss=41.093922002105195, w0=32.899999999999984, w1=1.237075808611071\n",
      "SubSGD iter. 47/499: loss=40.39392200210519, w0=33.59999999999999, w1=0.9061945188168505\n",
      "SubSGD iter. 48/499: loss=39.69419701964712, w0=34.29999999999999, w1=0.6997263763701098\n",
      "SubSGD iter. 49/499: loss=38.99467413848178, w0=34.99999999999999, w1=0.013734344880615201\n",
      "SubSGD iter. 50/499: loss=38.296664244569484, w0=35.699999999999996, w1=0.035696162867201814\n",
      "SubSGD iter. 51/499: loss=37.597308093359636, w0=36.4, w1=0.29557302918286976\n",
      "SubSGD iter. 52/499: loss=36.897311519267966, w0=37.1, w1=0.5455695783741176\n",
      "SubSGD iter. 53/499: loss=36.19734675107514, w0=37.800000000000004, w1=-0.10560672279774008\n",
      "SubSGD iter. 54/499: loss=35.501693862336595, w0=38.50000000000001, w1=0.37330398296192907\n",
      "SubSGD iter. 55/499: loss=34.80055339616959, w0=39.20000000000001, w1=0.016288157802013314\n",
      "SubSGD iter. 56/499: loss=34.10497986988331, w0=39.90000000000001, w1=1.0074942142651953\n",
      "SubSGD iter. 57/499: loss=33.40007931185142, w0=40.600000000000016, w1=2.0616755822032418\n",
      "SubSGD iter. 58/499: loss=32.696722633891284, w0=41.30000000000002, w1=3.12301506450204\n",
      "SubSGD iter. 59/499: loss=31.99479230945289, w0=42.00000000000002, w1=3.1305037287881565\n",
      "SubSGD iter. 60/499: loss=31.29523868576272, w0=42.700000000000024, w1=2.85879601451591\n",
      "SubSGD iter. 61/499: loss=30.596849374461513, w0=43.40000000000003, w1=3.8433262664813554\n",
      "SubSGD iter. 62/499: loss=29.89488368289421, w0=44.10000000000003, w1=3.405745440920037\n",
      "SubSGD iter. 63/499: loss=29.196887223765977, w0=44.80000000000003, w1=3.246720908328294\n",
      "SubSGD iter. 64/499: loss=28.498647255354708, w0=45.500000000000036, w1=2.7737849169813984\n",
      "SubSGD iter. 65/499: loss=27.80406453020897, w0=46.20000000000004, w1=2.6900944451242164\n",
      "SubSGD iter. 66/499: loss=27.10807695727628, w0=46.90000000000004, w1=2.932589212864402\n",
      "SubSGD iter. 67/499: loss=26.40894973189339, w0=47.600000000000044, w1=3.8741950780216365\n",
      "SubSGD iter. 68/499: loss=25.702787065267387, w0=48.30000000000005, w1=2.8176190227523437\n",
      "SubSGD iter. 69/499: loss=25.02384849083648, w0=49.00000000000005, w1=3.4650992576234776\n",
      "SubSGD iter. 70/499: loss=24.31647100998004, w0=49.70000000000005, w1=3.2746169448905187\n",
      "SubSGD iter. 71/499: loss=23.6312207974793, w0=50.400000000000055, w1=2.5831210781690004\n",
      "SubSGD iter. 72/499: loss=22.983485658541028, w0=51.10000000000006, w1=3.5539779355626844\n",
      "SubSGD iter. 73/499: loss=22.249301119137595, w0=51.80000000000006, w1=4.257906894466875\n",
      "SubSGD iter. 74/499: loss=21.535939159083537, w0=52.500000000000064, w1=5.48299403535624\n",
      "SubSGD iter. 75/499: loss=20.813427704087456, w0=53.20000000000007, w1=6.348180534142212\n",
      "SubSGD iter. 76/499: loss=20.1072462133966, w0=53.90000000000007, w1=7.504079250421279\n",
      "SubSGD iter. 77/499: loss=19.401695972869025, w0=54.60000000000007, w1=6.449495707645731\n",
      "SubSGD iter. 78/499: loss=18.719364900109202, w0=55.300000000000075, w1=6.326998909233739\n",
      "SubSGD iter. 79/499: loss=18.03624757988762, w0=56.00000000000008, w1=6.170733514991505\n",
      "SubSGD iter. 80/499: loss=17.36296752325302, w0=56.70000000000008, w1=5.988817483777389\n",
      "SubSGD iter. 81/499: loss=16.703942866432804, w0=57.400000000000084, w1=6.435834423852655\n",
      "SubSGD iter. 82/499: loss=16.006506724356882, w0=58.10000000000009, w1=7.150307048650502\n",
      "SubSGD iter. 83/499: loss=15.292388922809474, w0=58.80000000000009, w1=8.259068541718849\n",
      "SubSGD iter. 84/499: loss=14.563665729450655, w0=59.50000000000009, w1=8.14226268617017\n",
      "SubSGD iter. 85/499: loss=13.901299672486005, w0=60.200000000000095, w1=8.93369757663848\n",
      "SubSGD iter. 86/499: loss=13.193108279496364, w0=60.9000000000001, w1=7.782860853784114\n",
      "SubSGD iter. 87/499: loss=12.641760162927403, w0=61.6000000000001, w1=8.145339118231608\n",
      "SubSGD iter. 88/499: loss=11.975372006609819, w0=62.300000000000104, w1=7.904019643663368\n",
      "SubSGD iter. 89/499: loss=11.408932253344195, w0=63.00000000000011, w1=7.305322202059305\n",
      "SubSGD iter. 90/499: loss=10.977026637129427, w0=63.70000000000011, w1=6.269463306511421\n",
      "SubSGD iter. 91/499: loss=10.808414103225227, w0=64.4000000000001, w1=5.905750708732519\n",
      "SubSGD iter. 92/499: loss=10.516930544877804, w0=63.7000000000001, w1=6.856197013402831\n",
      "SubSGD iter. 93/499: loss=10.599175570743597, w0=64.4000000000001, w1=7.210930703318239\n",
      "SubSGD iter. 94/499: loss=10.000328698134657, w0=63.7000000000001, w1=9.085122838194799\n",
      "SubSGD iter. 95/499: loss=10.044419761930849, w0=63.0000000000001, w1=9.38294988790977\n",
      "SubSGD iter. 96/499: loss=10.597182804357379, w0=63.7000000000001, w1=9.417459008377952\n",
      "SubSGD iter. 97/499: loss=9.99459702657947, w0=64.4000000000001, w1=9.546531836529965\n",
      "SubSGD iter. 98/499: loss=9.401326408200129, w0=65.10000000000011, w1=9.912243120307192\n",
      "SubSGD iter. 99/499: loss=8.78972552967123, w0=65.80000000000011, w1=9.72651607699782\n",
      "SubSGD iter. 100/499: loss=8.308170108956784, w0=65.10000000000011, w1=10.855488144175487\n",
      "SubSGD iter. 101/499: loss=8.659038749200084, w0=65.80000000000011, w1=10.249013985728844\n",
      "SubSGD iter. 102/499: loss=8.201957504131409, w0=65.10000000000011, w1=11.529307365835539\n",
      "SubSGD iter. 103/499: loss=8.595028003680735, w0=65.80000000000011, w1=10.49355358960562\n",
      "SubSGD iter. 104/499: loss=8.159787653952003, w0=66.50000000000011, w1=10.329437701176468\n",
      "SubSGD iter. 105/499: loss=7.687582777026676, w0=67.20000000000012, w1=10.476877337610576\n",
      "SubSGD iter. 106/499: loss=7.188467278417329, w0=67.90000000000012, w1=9.486881076209134\n",
      "SubSGD iter. 107/499: loss=7.089256855368365, w0=68.60000000000012, w1=9.145887831652669\n",
      "SubSGD iter. 108/499: loss=6.894948409028523, w0=69.30000000000013, w1=8.787625994714006\n",
      "SubSGD iter. 109/499: loss=6.787935948759678, w0=68.60000000000012, w1=9.1335683038369\n",
      "SubSGD iter. 110/499: loss=6.90037457826617, w0=69.30000000000013, w1=8.132945562598639\n",
      "SubSGD iter. 111/499: loss=7.129028998466059, w0=70.00000000000013, w1=9.03041422093219\n",
      "SubSGD iter. 112/499: loss=6.436738289066318, w0=69.30000000000013, w1=9.760777663175947\n",
      "SubSGD iter. 113/499: loss=6.337381401128034, w0=68.60000000000012, w1=9.767186572996167\n",
      "SubSGD iter. 114/499: loss=6.637785334311052, w0=69.30000000000013, w1=10.08228099519684\n",
      "SubSGD iter. 115/499: loss=6.20647086042751, w0=70.00000000000013, w1=11.308174301773699\n",
      "SubSGD iter. 116/499: loss=5.497634848628221, w0=69.30000000000013, w1=10.98522615541852\n",
      "SubSGD iter. 117/499: loss=5.89137423398824, w0=70.00000000000013, w1=10.378829409056781\n",
      "SubSGD iter. 118/499: loss=5.82133128808053, w0=70.70000000000013, w1=10.883430561926117\n",
      "SubSGD iter. 119/499: loss=5.398171275635684, w0=71.40000000000013, w1=11.44657584629461\n",
      "SubSGD iter. 120/499: loss=5.013454077056701, w0=72.10000000000014, w1=12.386065815180807\n",
      "SubSGD iter. 121/499: loss=4.628509012544409, w0=72.80000000000014, w1=12.842226370043328\n",
      "SubSGD iter. 122/499: loss=4.47926278484161, w0=72.10000000000014, w1=13.353708694822819\n",
      "SubSGD iter. 123/499: loss=4.5191312642905705, w0=72.80000000000014, w1=12.705463982197331\n",
      "SubSGD iter. 124/499: loss=4.497486842415434, w0=73.50000000000014, w1=13.888824520476264\n",
      "SubSGD iter. 125/499: loss=4.439647892017602, w0=74.20000000000014, w1=13.566219264407403\n",
      "SubSGD iter. 126/499: loss=4.494186783555086, w0=74.90000000000015, w1=12.878363604272318\n",
      "SubSGD iter. 127/499: loss=4.662866342245249, w0=74.20000000000014, w1=13.312905529293245\n",
      "SubSGD iter. 128/499: loss=4.49825419701835, w0=74.90000000000015, w1=11.561544718183976\n",
      "SubSGD iter. 129/499: loss=4.923695655799264, w0=75.60000000000015, w1=11.32689909232793\n",
      "SubSGD iter. 130/499: loss=5.167661358696178, w0=74.90000000000015, w1=10.748580902697372\n",
      "SubSGD iter. 131/499: loss=5.206982950555518, w0=74.20000000000014, w1=10.827600057074958\n",
      "SubSGD iter. 132/499: loss=5.070493836381185, w0=74.90000000000015, w1=11.085273366431199\n",
      "SubSGD iter. 133/499: loss=5.078879020867907, w0=74.20000000000014, w1=11.56977151998304\n",
      "SubSGD iter. 134/499: loss=4.80443836797549, w0=74.90000000000015, w1=12.45067829746747\n",
      "SubSGD iter. 135/499: loss=4.718982409843452, w0=75.60000000000015, w1=11.793008227971637\n",
      "SubSGD iter. 136/499: loss=5.041076931635562, w0=76.30000000000015, w1=12.188585388237723\n",
      "SubSGD iter. 137/499: loss=5.208670035723569, w0=77.00000000000016, w1=12.696104298561025\n",
      "SubSGD iter. 138/499: loss=5.447630978062711, w0=77.70000000000016, w1=12.883226534631072\n",
      "SubSGD iter. 139/499: loss=5.799901941463431, w0=77.00000000000016, w1=13.568909473364291\n",
      "SubSGD iter. 140/499: loss=5.409484153738624, w0=77.70000000000016, w1=13.394518034691727\n",
      "SubSGD iter. 141/499: loss=5.783842808593472, w0=78.40000000000016, w1=12.809125871073295\n",
      "SubSGD iter. 142/499: loss=6.221818069806464, w0=77.70000000000016, w1=13.985216282676049\n",
      "SubSGD iter. 143/499: loss=5.800779643326976, w0=77.00000000000016, w1=13.209865012680119\n",
      "SubSGD iter. 144/499: loss=5.414413198589352, w0=76.30000000000015, w1=12.660743899352811\n",
      "SubSGD iter. 145/499: loss=5.141463465373001, w0=75.60000000000015, w1=11.088313103059715\n",
      "SubSGD iter. 146/499: loss=5.244323381824703, w0=76.30000000000015, w1=10.88081265310528\n",
      "SubSGD iter. 147/499: loss=5.534783665714113, w0=77.00000000000016, w1=11.490248612386218\n",
      "SubSGD iter. 148/499: loss=5.646723054587963, w0=76.30000000000015, w1=12.692146459149935\n",
      "SubSGD iter. 149/499: loss=5.1380103161164845, w0=75.60000000000015, w1=12.63639107554917\n",
      "SubSGD iter. 150/499: loss=4.889905309506226, w0=74.90000000000015, w1=11.579705402783265\n",
      "SubSGD iter. 151/499: loss=4.918387329428227, w0=75.60000000000015, w1=12.125722679574597\n",
      "SubSGD iter. 152/499: loss=4.970410884675549, w0=74.90000000000015, w1=12.615769553055175\n",
      "SubSGD iter. 153/499: loss=4.693994987707961, w0=74.20000000000014, w1=12.411000242969736\n",
      "SubSGD iter. 154/499: loss=4.596009926484173, w0=73.50000000000014, w1=12.646097629738101\n",
      "SubSGD iter. 155/499: loss=4.4974564296449495, w0=72.80000000000014, w1=12.856433602155832\n",
      "SubSGD iter. 156/499: loss=4.477571355161033, w0=72.10000000000014, w1=11.344494380575366\n",
      "SubSGD iter. 157/499: loss=4.91264006489084, w0=71.40000000000013, w1=13.200371507336577\n",
      "SubSGD iter. 158/499: loss=4.672377088060559, w0=72.10000000000014, w1=13.710909746799208\n",
      "SubSGD iter. 159/499: loss=4.517385162957631, w0=72.80000000000014, w1=13.89694034965166\n",
      "SubSGD iter. 160/499: loss=4.447014963662984, w0=72.10000000000014, w1=12.906669428713233\n",
      "SubSGD iter. 161/499: loss=4.550894504905591, w0=72.80000000000014, w1=13.423514606257012\n",
      "SubSGD iter. 162/499: loss=4.439269321584244, w0=73.50000000000014, w1=13.787592656958928\n",
      "SubSGD iter. 163/499: loss=4.434757555950685, w0=72.80000000000014, w1=13.162204022212086\n",
      "SubSGD iter. 164/499: loss=4.450130167619956, w0=72.10000000000014, w1=14.123456988127018\n",
      "SubSGD iter. 165/499: loss=4.540343970875131, w0=71.40000000000013, w1=14.762084816149526\n",
      "SubSGD iter. 166/499: loss=4.767483264401827, w0=72.10000000000014, w1=15.47934808397645\n",
      "SubSGD iter. 167/499: loss=4.78733239572112, w0=72.80000000000014, w1=15.943677363783987\n",
      "SubSGD iter. 168/499: loss=4.8547408173222415, w0=72.10000000000014, w1=15.458566402635249\n",
      "SubSGD iter. 169/499: loss=4.781737941215403, w0=72.80000000000014, w1=14.496426443473883\n",
      "SubSGD iter. 170/499: loss=4.507268845645554, w0=73.50000000000014, w1=12.627985458356482\n",
      "SubSGD iter. 171/499: loss=4.500279584459529, w0=74.20000000000014, w1=13.734439671746632\n",
      "SubSGD iter. 172/499: loss=4.49740711316392, w0=74.90000000000015, w1=14.19980700059713\n",
      "SubSGD iter. 173/499: loss=4.658868712583056, w0=75.60000000000015, w1=13.494482138276679\n",
      "SubSGD iter. 174/499: loss=4.829566436423222, w0=74.90000000000015, w1=13.918826844747935\n",
      "SubSGD iter. 175/499: loss=4.638166181675335, w0=74.20000000000014, w1=14.51585834435891\n",
      "SubSGD iter. 176/499: loss=4.568447419817449, w0=73.50000000000014, w1=15.087846183402716\n",
      "SubSGD iter. 177/499: loss=4.61089245521587, w0=72.80000000000014, w1=14.605157011054466\n",
      "SubSGD iter. 178/499: loss=4.524161633840592, w0=73.50000000000014, w1=13.346079645571185\n",
      "SubSGD iter. 179/499: loss=4.432200109786436, w0=72.80000000000014, w1=13.904202992204324\n",
      "SubSGD iter. 180/499: loss=4.447394678208298, w0=72.10000000000014, w1=12.471108678720714\n",
      "SubSGD iter. 181/499: loss=4.6127468833012575, w0=72.80000000000014, w1=12.37840948221266\n",
      "SubSGD iter. 182/499: loss=4.553054638868279, w0=72.10000000000014, w1=13.176532210399975\n",
      "SubSGD iter. 183/499: loss=4.5279863087682735, w0=71.40000000000013, w1=12.78429977155171\n",
      "SubSGD iter. 184/499: loss=4.710416003951658, w0=72.10000000000014, w1=13.030075963737126\n",
      "SubSGD iter. 185/499: loss=4.539030287597859, w0=72.80000000000014, w1=13.40827085479059\n",
      "SubSGD iter. 186/499: loss=4.4396109742888985, w0=72.10000000000014, w1=13.535906884487297\n",
      "SubSGD iter. 187/499: loss=4.515632326704933, w0=71.40000000000013, w1=13.930617202239716\n",
      "SubSGD iter. 188/499: loss=4.6715062552480475, w0=72.10000000000014, w1=14.806645884638765\n",
      "SubSGD iter. 189/499: loss=4.633345920783382, w0=71.40000000000013, w1=15.5199078798825\n",
      "SubSGD iter. 190/499: loss=4.934973165578511, w0=72.10000000000014, w1=15.554288986764194\n",
      "SubSGD iter. 191/499: loss=4.807975094505691, w0=72.80000000000014, w1=15.357489791839953\n",
      "SubSGD iter. 192/499: loss=4.682499501007851, w0=72.10000000000014, w1=14.370948868676818\n",
      "SubSGD iter. 193/499: loss=4.5665091518775105, w0=71.40000000000013, w1=14.310942257250748\n",
      "SubSGD iter. 194/499: loss=4.703575401319844, w0=70.70000000000013, w1=13.133913200198261\n",
      "SubSGD iter. 195/499: loss=4.890423673154925, w0=70.00000000000013, w1=12.205008885472386\n",
      "SubSGD iter. 196/499: loss=5.281388693164074, w0=69.30000000000013, w1=12.521457876527228\n",
      "SubSGD iter. 197/499: loss=5.56205593313641, w0=68.60000000000012, w1=12.650899034677035\n",
      "SubSGD iter. 198/499: loss=5.938104481585913, w0=67.90000000000012, w1=11.860378245810349\n",
      "SubSGD iter. 199/499: loss=6.4679491250265295, w0=68.60000000000012, w1=12.734911222097304\n",
      "SubSGD iter. 200/499: loss=5.93024510052433, w0=69.30000000000013, w1=13.00859288294788\n",
      "SubSGD iter. 201/499: loss=5.514743188810472, w0=68.60000000000012, w1=13.562756885297652\n",
      "SubSGD iter. 202/499: loss=5.893664431666251, w0=69.30000000000013, w1=14.791267663622254\n",
      "SubSGD iter. 203/499: loss=5.58123696619127, w0=70.00000000000013, w1=15.176562249555927\n",
      "SubSGD iter. 204/499: loss=5.318590384915419, w0=70.70000000000013, w1=15.549049236936586\n",
      "SubSGD iter. 205/499: loss=5.141320989286275, w0=71.40000000000013, w1=15.149817734033677\n",
      "SubSGD iter. 206/499: loss=4.84440952042823, w0=72.10000000000014, w1=15.608913463580631\n",
      "SubSGD iter. 207/499: loss=4.82339465162771, w0=72.80000000000014, w1=14.192065780221691\n",
      "SubSGD iter. 208/499: loss=4.469734418733381, w0=73.50000000000014, w1=13.904228677342747\n",
      "SubSGD iter. 209/499: loss=4.440539943479648, w0=72.80000000000014, w1=14.0397865544169\n",
      "SubSGD iter. 210/499: loss=4.456233769054959, w0=73.50000000000014, w1=14.21299011836738\n",
      "SubSGD iter. 211/499: loss=4.466305580380948, w0=72.80000000000014, w1=14.592518456555123\n",
      "SubSGD iter. 212/499: loss=4.522131367861359, w0=72.10000000000014, w1=15.006320515931494\n",
      "SubSGD iter. 213/499: loss=4.672987904190277, w0=72.80000000000014, w1=13.431903138652293\n",
      "SubSGD iter. 214/499: loss=4.439104036091585, w0=72.10000000000014, w1=12.892918893817924\n",
      "SubSGD iter. 215/499: loss=4.552371785328162, w0=72.80000000000014, w1=13.177829302148313\n",
      "SubSGD iter. 216/499: loss=4.449181094577654, w0=73.50000000000014, w1=13.247933549227746\n",
      "SubSGD iter. 217/499: loss=4.436213771925812, w0=74.20000000000014, w1=12.684695270025296\n",
      "SubSGD iter. 218/499: loss=4.552704287255046, w0=73.50000000000014, w1=13.963396825294758\n",
      "SubSGD iter. 219/499: loss=4.444282483003087, w0=72.80000000000014, w1=14.578875353349224\n",
      "SubSGD iter. 220/499: loss=4.51996003065446, w0=72.10000000000014, w1=12.884021004470949\n",
      "SubSGD iter. 221/499: loss=4.553337964461024, w0=72.80000000000014, w1=13.134584794951985\n",
      "SubSGD iter. 222/499: loss=4.451923100715819, w0=72.10000000000014, w1=14.196360135602296\n",
      "SubSGD iter. 223/499: loss=4.547176158606178, w0=72.80000000000014, w1=13.603664335499973\n",
      "SubSGD iter. 224/499: loss=4.438147988283249, w0=73.50000000000014, w1=14.346235405729258\n",
      "SubSGD iter. 225/499: loss=4.481672933894781, w0=72.80000000000014, w1=14.071346639880492\n",
      "SubSGD iter. 226/499: loss=4.458707143105752, w0=73.50000000000014, w1=13.652765484611624\n",
      "SubSGD iter. 227/499: loss=4.4306367655774945, w0=74.20000000000014, w1=14.985005273313138\n",
      "SubSGD iter. 228/499: loss=4.65270954759441, w0=73.50000000000014, w1=15.24646433077117\n",
      "SubSGD iter. 229/499: loss=4.648543217706109, w0=74.20000000000014, w1=15.237031498558656\n",
      "SubSGD iter. 230/499: loss=4.709553809378047, w0=73.50000000000014, w1=15.25397990984339\n",
      "SubSGD iter. 231/499: loss=4.650401461497223, w0=72.80000000000014, w1=15.509961282271439\n",
      "SubSGD iter. 232/499: loss=4.723281462492875, w0=72.10000000000014, w1=14.927336294646473\n",
      "SubSGD iter. 233/499: loss=4.656662316176097, w0=72.80000000000014, w1=14.129932265917958\n",
      "SubSGD iter. 234/499: loss=4.463768857688478, w0=72.10000000000014, w1=12.893345602553268\n",
      "SubSGD iter. 235/499: loss=4.552325505341007, w0=72.80000000000014, w1=11.76961717697156\n",
      "SubSGD iter. 236/499: loss=4.70264626366703, w0=72.10000000000014, w1=12.466445018700801\n",
      "SubSGD iter. 237/499: loss=4.613586929340726, w0=72.80000000000014, w1=12.926212195183762\n",
      "SubSGD iter. 238/499: loss=4.469851147218389, w0=73.50000000000014, w1=13.895904580546064\n",
      "SubSGD iter. 239/499: loss=4.44005262407659, w0=72.80000000000014, w1=13.838418954519957\n",
      "SubSGD iter. 240/499: loss=4.444186452094344, w0=73.50000000000014, w1=13.517392413499913\n",
      "SubSGD iter. 241/499: loss=4.429349141479579, w0=74.20000000000014, w1=12.480301434311096\n",
      "SubSGD iter. 242/499: loss=4.583872179120662, w0=73.50000000000014, w1=14.075865595336786\n",
      "SubSGD iter. 243/499: loss=4.4529531116630485, w0=72.80000000000014, w1=15.07800267494068\n",
      "SubSGD iter. 244/499: loss=4.615361882793538, w0=72.10000000000014, w1=15.388791572078327\n",
      "SubSGD iter. 245/499: loss=4.763310309474897, w0=72.80000000000014, w1=14.980061139804006\n",
      "SubSGD iter. 246/499: loss=4.594151512203162, w0=72.10000000000014, w1=14.947132934045097\n",
      "SubSGD iter. 247/499: loss=4.660674531233994, w0=71.40000000000013, w1=14.932817229768489\n",
      "SubSGD iter. 248/499: loss=4.798934784866724, w0=72.10000000000014, w1=13.96384583905846\n",
      "SubSGD iter. 249/499: loss=4.528172710816101, w0=72.80000000000014, w1=15.114754232095553\n",
      "SubSGD iter. 250/499: loss=4.623687120766066, w0=72.10000000000014, w1=15.657851673563911\n",
      "SubSGD iter. 251/499: loss=4.837494274656411, w0=72.80000000000014, w1=14.964996745052316\n",
      "SubSGD iter. 252/499: loss=4.591013965265538, w0=72.10000000000014, w1=14.84662036333167\n",
      "SubSGD iter. 253/499: loss=4.640836615677904, w0=71.40000000000013, w1=14.121584073578761\n",
      "SubSGD iter. 254/499: loss=4.684789983233513, w0=72.10000000000014, w1=12.51551062326293\n",
      "SubSGD iter. 255/499: loss=4.604901635408609, w0=72.80000000000014, w1=12.274414205431182\n",
      "SubSGD iter. 256/499: loss=4.574656726003929, w0=72.10000000000014, w1=11.614722413142909\n",
      "SubSGD iter. 257/499: loss=4.824467295260229, w0=72.80000000000014, w1=12.120748146601596\n",
      "SubSGD iter. 258/499: loss=4.609853967104627, w0=72.10000000000014, w1=12.363283787630301\n",
      "SubSGD iter. 259/499: loss=4.632909529000507, w0=71.40000000000013, w1=11.929123165796511\n",
      "SubSGD iter. 260/499: loss=4.872141587969004, w0=72.10000000000014, w1=11.278297445907205\n",
      "SubSGD iter. 261/499: loss=4.93585478110221, w0=72.80000000000014, w1=10.930838470542058\n",
      "SubSGD iter. 262/499: loss=4.994363799806157, w0=73.50000000000014, w1=12.008700235221072\n",
      "SubSGD iter. 263/499: loss=4.626509013119339, w0=74.20000000000014, w1=11.78296840514714\n",
      "SubSGD iter. 264/499: loss=4.741634891084137, w0=74.90000000000015, w1=11.753021109180933\n",
      "SubSGD iter. 265/499: loss=4.869750667049453, w0=75.60000000000015, w1=11.212455224083037\n",
      "SubSGD iter. 266/499: loss=5.2034527690329835, w0=74.90000000000015, w1=11.600227694882756\n",
      "SubSGD iter. 267/499: loss=4.9124428603348544, w0=74.20000000000014, w1=10.395828473396476\n",
      "SubSGD iter. 268/499: loss=5.2563127335833455, w0=73.50000000000014, w1=11.014288697879426\n",
      "SubSGD iter. 269/499: loss=4.948775804606681, w0=74.20000000000014, w1=11.492963070251934\n",
      "SubSGD iter. 270/499: loss=4.82871389491765, w0=74.90000000000015, w1=12.669026863894842\n",
      "SubSGD iter. 271/499: loss=4.68681528095098, w0=75.60000000000015, w1=14.078137345282004\n",
      "SubSGD iter. 272/499: loss=4.846955739651099, w0=74.90000000000015, w1=15.279102863412927\n",
      "SubSGD iter. 273/499: loss=4.845932092361497, w0=74.20000000000014, w1=15.636271477773805\n",
      "SubSGD iter. 274/499: loss=4.815792971504191, w0=73.50000000000014, w1=15.386760507538035\n",
      "SubSGD iter. 275/499: loss=4.684559192491783, w0=72.80000000000014, w1=15.925364132038064\n",
      "SubSGD iter. 276/499: loss=4.848741447778265, w0=73.50000000000014, w1=15.846558893428547\n",
      "SubSGD iter. 277/499: loss=4.8195586446622185, w0=74.20000000000014, w1=16.405632786818128\n",
      "SubSGD iter. 278/499: loss=5.071157474558965, w0=73.50000000000014, w1=16.793537244969766\n",
      "SubSGD iter. 279/499: loss=5.167485420342024, w0=72.80000000000014, w1=15.575288090442207\n",
      "SubSGD iter. 280/499: loss=4.741587040152827, w0=73.50000000000014, w1=16.155929915603902\n",
      "SubSGD iter. 281/499: loss=4.922920906773422, w0=72.80000000000014, w1=15.924968844793101\n",
      "SubSGD iter. 282/499: loss=4.848612154577262, w0=73.50000000000014, w1=15.598836949850428\n",
      "SubSGD iter. 283/499: loss=4.744028382178312, w0=74.20000000000014, w1=15.94071150455548\n",
      "SubSGD iter. 284/499: loss=4.909291041409887, w0=73.50000000000014, w1=15.67282226947715\n",
      "SubSGD iter. 285/499: loss=4.765899582708778, w0=74.20000000000014, w1=16.432373648798\n",
      "SubSGD iter. 286/499: loss=5.081090952796319, w0=74.90000000000015, w1=15.207026824036282\n",
      "SubSGD iter. 287/499: loss=4.82880784779486, w0=74.20000000000014, w1=15.5179682190157\n",
      "SubSGD iter. 288/499: loss=4.78228725279554, w0=74.90000000000015, w1=14.340122962261205\n",
      "SubSGD iter. 289/499: loss=4.6740659333997385, w0=75.60000000000015, w1=15.124450532173473\n",
      "SubSGD iter. 290/499: loss=4.999104854295668, w0=76.30000000000015, w1=14.909236348876046\n",
      "SubSGD iter. 291/499: loss=5.209014841810698, w0=75.60000000000015, w1=15.318890170623579\n",
      "SubSGD iter. 292/499: loss=5.04388849792556, w0=74.90000000000015, w1=15.644255419615291\n",
      "SubSGD iter. 293/499: loss=4.942229880136223, w0=75.60000000000015, w1=15.549957982146275\n",
      "SubSGD iter. 294/499: loss=5.102699763404073, w0=76.30000000000015, w1=14.227350039690995\n",
      "SubSGD iter. 295/499: loss=5.119232925012862, w0=77.00000000000016, w1=14.127720693942194\n",
      "SubSGD iter. 296/499: loss=5.432300364304593, w0=77.70000000000016, w1=14.554171826199926\n",
      "SubSGD iter. 297/499: loss=5.848751974395907, w0=78.40000000000016, w1=14.435189247807104\n",
      "SubSGD iter. 298/499: loss=6.25988977805946, w0=77.70000000000016, w1=14.437267928934233\n",
      "SubSGD iter. 299/499: loss=5.836317083088961, w0=77.00000000000016, w1=14.539963448856605\n",
      "SubSGD iter. 300/499: loss=5.472572866134903, w0=76.30000000000015, w1=14.264362801261822\n",
      "SubSGD iter. 301/499: loss=5.122631153013636, w0=75.60000000000015, w1=15.382527935978965\n",
      "SubSGD iter. 302/499: loss=5.0595421558527836, w0=74.90000000000015, w1=15.591480767039053\n",
      "SubSGD iter. 303/499: loss=4.92735648581856, w0=74.20000000000014, w1=15.868939111332335\n",
      "SubSGD iter. 304/499: loss=4.886281104384455, w0=74.90000000000015, w1=15.642616525520028\n",
      "SubSGD iter. 305/499: loss=4.941765253003967, w0=75.60000000000015, w1=14.295496312741296\n",
      "SubSGD iter. 306/499: loss=4.8655449378014595, w0=74.90000000000015, w1=14.497809153679523\n",
      "SubSGD iter. 307/499: loss=4.694692547493016, w0=74.20000000000014, w1=13.903148294300475\n",
      "SubSGD iter. 308/499: loss=4.505080012305678, w0=73.50000000000014, w1=13.101339008673099\n",
      "SubSGD iter. 309/499: loss=4.445307871474099, w0=72.80000000000014, w1=12.905297723014604\n",
      "SubSGD iter. 310/499: loss=4.472083136857003, w0=73.50000000000014, w1=13.46562184521122\n",
      "SubSGD iter. 311/499: loss=4.429623823580292, w0=72.80000000000014, w1=14.483690977987925\n",
      "SubSGD iter. 312/499: loss=4.505417342598548, w0=73.50000000000014, w1=12.770115226288022\n",
      "SubSGD iter. 313/499: loss=4.4794732693426, w0=72.80000000000014, w1=14.23777177960029\n",
      "SubSGD iter. 314/499: loss=4.474476770271002, w0=73.50000000000014, w1=15.213614104812411\n",
      "SubSGD iter. 315/499: loss=4.640510152018961, w0=72.80000000000014, w1=15.413049370942984\n",
      "SubSGD iter. 316/499: loss=4.696956296153655, w0=73.50000000000014, w1=14.055531378391592\n",
      "SubSGD iter. 317/499: loss=4.451238424372152, w0=74.20000000000014, w1=13.435917205542147\n",
      "SubSGD iter. 318/499: loss=4.495072780479242, w0=73.50000000000014, w1=12.907866416213674\n",
      "SubSGD iter. 319/499: loss=4.462880988676354, w0=72.80000000000014, w1=12.048810861969994\n",
      "SubSGD iter. 320/499: loss=4.627613552365083, w0=73.50000000000014, w1=12.0029293766667\n",
      "SubSGD iter. 321/499: loss=4.627963379617754, w0=72.80000000000014, w1=11.053961424987795\n",
      "SubSGD iter. 322/499: loss=4.945310053275005, w0=72.10000000000014, w1=12.004504363839805\n",
      "SubSGD iter. 323/499: loss=4.713808392068536, w0=72.80000000000014, w1=11.17842695912208\n",
      "SubSGD iter. 324/499: loss=4.897746566216727, w0=73.50000000000014, w1=11.157895266417858\n",
      "SubSGD iter. 325/499: loss=4.894340720449688, w0=74.20000000000014, w1=12.959343370624708\n",
      "SubSGD iter. 326/499: loss=4.520991204342403, w0=74.90000000000015, w1=12.9124955558804\n",
      "SubSGD iter. 327/499: loss=4.659588106905491, w0=74.20000000000014, w1=11.925116797279317\n",
      "SubSGD iter. 328/499: loss=4.703868941429154, w0=73.50000000000014, w1=10.973863531555216\n",
      "SubSGD iter. 329/499: loss=4.964542523007311, w0=74.20000000000014, w1=11.729105322695728\n",
      "SubSGD iter. 330/499: loss=4.756752411470436, w0=74.90000000000015, w1=12.037005513172833\n",
      "SubSGD iter. 331/499: loss=4.799169419958921, w0=74.20000000000014, w1=11.361672071127202\n",
      "SubSGD iter. 332/499: loss=4.871718561923712, w0=74.90000000000015, w1=11.36364644993207\n",
      "SubSGD iter. 333/499: loss=4.984287818860987, w0=74.20000000000014, w1=12.393043604306508\n",
      "SubSGD iter. 334/499: loss=4.599331910712043, w0=73.50000000000014, w1=13.029891203497279\n",
      "SubSGD iter. 335/499: loss=4.450953727090642, w0=72.80000000000014, w1=13.651273610906344\n",
      "SubSGD iter. 336/499: loss=4.438628935820166, w0=72.10000000000014, w1=12.236922397988069\n",
      "SubSGD iter. 337/499: loss=4.658868383829744, w0=71.40000000000013, w1=12.838605611980991\n",
      "SubSGD iter. 338/499: loss=4.703655743574194, w0=70.70000000000013, w1=13.322140276180802\n",
      "SubSGD iter. 339/499: loss=4.880610377431268, w0=70.00000000000013, w1=14.081697293968155\n",
      "SubSGD iter. 340/499: loss=5.171317493156397, w0=70.70000000000013, w1=14.576962147586617\n",
      "SubSGD iter. 341/499: loss=4.946638433413724, w0=70.00000000000013, w1=15.700537128720683\n",
      "SubSGD iter. 342/499: loss=5.437359979781938, w0=70.70000000000013, w1=16.02023687105277\n",
      "SubSGD iter. 343/499: loss=5.273805402637996, w0=71.40000000000013, w1=16.713579820270557\n",
      "SubSGD iter. 344/499: loss=5.326468832443648, w0=72.10000000000014, w1=17.018062307278274\n",
      "SubSGD iter. 345/499: loss=5.327427853082639, w0=72.80000000000014, w1=17.311429460911214\n",
      "SubSGD iter. 346/499: loss=5.39539662702884, w0=73.50000000000014, w1=17.47591702995551\n",
      "SubSGD iter. 347/499: loss=5.4668283204267984, w0=74.20000000000014, w1=16.3642265510069\n",
      "SubSGD iter. 348/499: loss=5.055875943658254, w0=74.90000000000015, w1=15.409836225477582\n",
      "SubSGD iter. 349/499: loss=4.878643969351336, w0=75.60000000000015, w1=14.000209992089575\n",
      "SubSGD iter. 350/499: loss=4.84188881539467, w0=76.30000000000015, w1=13.49343033443176\n",
      "SubSGD iter. 351/499: loss=5.090875562256169, w0=77.00000000000016, w1=12.740863488686019\n",
      "SubSGD iter. 352/499: loss=5.443388929295296, w0=77.70000000000016, w1=12.387461481123308\n",
      "SubSGD iter. 353/499: loss=5.842131590022586, w0=77.00000000000016, w1=13.797535054783097\n",
      "SubSGD iter. 354/499: loss=5.41387064367357, w0=76.30000000000015, w1=13.5807048590698\n",
      "SubSGD iter. 355/499: loss=5.090576184369143, w0=77.00000000000016, w1=12.694212912809459\n",
      "SubSGD iter. 356/499: loss=5.447815615160573, w0=76.30000000000015, w1=12.758535192288484\n",
      "SubSGD iter. 357/499: loss=5.131047191986567, w0=75.60000000000015, w1=12.632897712809722\n",
      "SubSGD iter. 358/499: loss=4.890352998781842, w0=74.90000000000015, w1=12.933172722039764\n",
      "SubSGD iter. 359/499: loss=4.65768665245249, w0=75.60000000000015, w1=13.786145611421118\n",
      "SubSGD iter. 360/499: loss=4.832050309124873, w0=74.90000000000015, w1=13.4790530141749\n",
      "SubSGD iter. 361/499: loss=4.628931791921091, w0=74.20000000000014, w1=13.190036788334334\n",
      "SubSGD iter. 362/499: loss=4.503750327073642, w0=73.50000000000014, w1=13.028409596492656\n",
      "SubSGD iter. 363/499: loss=4.451083637062832, w0=72.80000000000014, w1=12.089458685767042\n",
      "SubSGD iter. 364/499: loss=4.617501248344233, w0=73.50000000000014, w1=11.224043678876983\n",
      "SubSGD iter. 365/499: loss=4.869974495151761, w0=72.80000000000014, w1=10.822286598277023\n",
      "SubSGD iter. 366/499: loss=5.039367908956189, w0=72.10000000000014, w1=12.399390284588629\n",
      "SubSGD iter. 367/499: loss=4.625978745409289, w0=72.80000000000014, w1=14.11903130824444\n",
      "SubSGD iter. 368/499: loss=4.462785292477856, w0=73.50000000000014, w1=13.68050259967418\n",
      "SubSGD iter. 369/499: loss=4.43125279600993, w0=72.80000000000014, w1=12.721763898389353\n",
      "SubSGD iter. 370/499: loss=4.495158162429076, w0=72.10000000000014, w1=13.146788901098903\n",
      "SubSGD iter. 371/499: loss=4.529971205299316, w0=72.80000000000014, w1=12.998297875365438\n",
      "SubSGD iter. 372/499: loss=4.462679416599268, w0=72.10000000000014, w1=12.924407651825566\n",
      "SubSGD iter. 373/499: loss=4.549037190489085, w0=71.40000000000013, w1=12.088481696518727\n",
      "SubSGD iter. 374/499: loss=4.833623993416234, w0=70.70000000000013, w1=11.313211252163299\n",
      "SubSGD iter. 375/499: loss=5.248859909550814, w0=71.40000000000013, w1=11.229693028206585\n",
      "SubSGD iter. 376/499: loss=5.087493183239979, w0=72.10000000000014, w1=11.685984075328852\n",
      "SubSGD iter. 377/499: loss=4.802686024127111, w0=72.80000000000014, w1=11.629963761787863\n",
      "SubSGD iter. 378/499: loss=4.743875641646884, w0=73.50000000000014, w1=12.039306595429839\n",
      "SubSGD iter. 379/499: loss=4.61890068022137, w0=74.20000000000014, w1=13.202720174941314\n",
      "SubSGD iter. 380/499: loss=4.5030651919348905, w0=74.90000000000015, w1=14.261999082695905\n",
      "SubSGD iter. 381/499: loss=4.6652079136027185, w0=74.20000000000014, w1=14.790535733831376\n",
      "SubSGD iter. 382/499: loss=4.613888266192645, w0=74.90000000000015, w1=13.537643314785221\n",
      "SubSGD iter. 383/499: loss=4.628565422694757, w0=74.20000000000014, w1=14.188302754614734\n",
      "SubSGD iter. 384/499: loss=4.527732607028878, w0=74.90000000000015, w1=13.734791097635462\n",
      "SubSGD iter. 385/499: loss=4.630925463811231, w0=74.20000000000014, w1=13.570485559516149\n",
      "SubSGD iter. 386/499: loss=4.494204221649517, w0=73.50000000000014, w1=13.215398537505093\n",
      "SubSGD iter. 387/499: loss=4.437936842670371, w0=72.80000000000014, w1=13.125303589904789\n",
      "SubSGD iter. 388/499: loss=4.4525572237506905, w0=72.10000000000014, w1=13.387423111556958\n",
      "SubSGD iter. 389/499: loss=4.51808437299777, w0=71.40000000000013, w1=13.254221557339617\n",
      "SubSGD iter. 390/499: loss=4.669464234349619, w0=70.70000000000013, w1=13.498885275135835\n",
      "SubSGD iter. 391/499: loss=4.876362840729399, w0=71.40000000000013, w1=13.363642319332149\n",
      "SubSGD iter. 392/499: loss=4.664949097764699, w0=72.10000000000014, w1=12.778850984359918\n",
      "SubSGD iter. 393/499: loss=4.56556289978848, w0=72.80000000000014, w1=12.443852103499838\n",
      "SubSGD iter. 394/499: loss=4.540571524290682, w0=72.10000000000014, w1=13.67032906436801\n",
      "SubSGD iter. 395/499: loss=4.516556580379421, w0=71.40000000000013, w1=12.750542135974941\n",
      "SubSGD iter. 396/499: loss=4.714829929735247, w0=72.10000000000014, w1=13.865425846347849\n",
      "SubSGD iter. 397/499: loss=4.522691664051269, w0=72.80000000000014, w1=14.164576312570514\n",
      "SubSGD iter. 398/499: loss=4.4670254261769875, w0=73.50000000000014, w1=13.964619309305379\n",
      "SubSGD iter. 399/499: loss=4.444366478118191, w0=74.20000000000014, w1=15.426378529723408\n",
      "SubSGD iter. 400/499: loss=4.757613504022114, w0=74.90000000000015, w1=15.294600300713638\n",
      "SubSGD iter. 401/499: loss=4.849696082215361, w0=74.20000000000014, w1=14.330115171235104\n",
      "SubSGD iter. 402/499: loss=4.543375109064487, w0=74.90000000000015, w1=14.578114311492392\n",
      "SubSGD iter. 403/499: loss=4.7065446612040835, w0=75.60000000000015, w1=15.590047373559143\n",
      "SubSGD iter. 404/499: loss=5.113528506561983, w0=74.90000000000015, w1=16.110710461179544\n",
      "SubSGD iter. 405/499: loss=5.086930617576654, w0=75.60000000000015, w1=15.873743726054643\n",
      "SubSGD iter. 406/499: loss=5.193860155904631, w0=74.90000000000015, w1=15.302022155881204\n",
      "SubSGD iter. 407/499: loss=4.851509451486659, w0=74.20000000000014, w1=14.488805068863208\n",
      "SubSGD iter. 408/499: loss=4.564467649589095, w0=73.50000000000014, w1=14.410846259206942\n",
      "SubSGD iter. 409/499: loss=4.48991028823239, w0=72.80000000000014, w1=14.981885106737993\n",
      "SubSGD iter. 410/499: loss=4.594534027553189, w0=72.10000000000014, w1=14.767398803042951\n",
      "SubSGD iter. 411/499: loss=4.62620927535117, w0=72.80000000000014, w1=15.374020181170671\n",
      "SubSGD iter. 412/499: loss=4.68677039180804, w0=73.50000000000014, w1=14.99687531709607\n",
      "SubSGD iter. 413/499: loss=4.590902968272891, w0=74.20000000000014, w1=15.179716716808207\n",
      "SubSGD iter. 414/499: loss=4.695987323105038, w0=73.50000000000014, w1=15.22954152504155\n",
      "SubSGD iter. 415/499: loss=4.644384477660072, w0=72.80000000000014, w1=14.926143290003106\n",
      "SubSGD iter. 416/499: loss=4.583047016876659, w0=73.50000000000014, w1=13.846924527336965\n",
      "SubSGD iter. 417/499: loss=4.437410082778783, w0=72.80000000000014, w1=13.717675492122098\n",
      "SubSGD iter. 418/499: loss=4.43986968671865, w0=72.10000000000014, w1=13.57407438649044\n",
      "SubSGD iter. 419/499: loss=4.515579568978912, w0=72.80000000000014, w1=13.73865796096815\n",
      "SubSGD iter. 420/499: loss=4.440443895368691, w0=72.10000000000014, w1=12.601352970864614\n",
      "SubSGD iter. 421/499: loss=4.590705740153512, w0=72.80000000000014, w1=13.371858733936829\n",
      "SubSGD iter. 422/499: loss=4.440532618280053, w0=72.10000000000014, w1=12.51619542425972\n",
      "SubSGD iter. 423/499: loss=4.604783300322543, w0=71.40000000000013, w1=13.180423777469407\n",
      "SubSGD iter. 424/499: loss=4.673552245293104, w0=72.10000000000014, w1=12.628946181113921\n",
      "SubSGD iter. 425/499: loss=4.586413568642506, w0=72.80000000000014, w1=13.234064615740088\n",
      "SubSGD iter. 426/499: loss=4.44604658500424, w0=73.50000000000014, w1=13.913568743857104\n",
      "SubSGD iter. 427/499: loss=4.441094650409706, w0=72.80000000000014, w1=13.244128933448856\n",
      "SubSGD iter. 428/499: loss=4.445535395342254, w0=72.10000000000014, w1=13.690595167177138\n",
      "SubSGD iter. 429/499: loss=4.516941051033941, w0=72.80000000000014, w1=13.363724891813163\n",
      "SubSGD iter. 430/499: loss=4.440762720579233, w0=73.50000000000014, w1=12.793122311422422\n",
      "SubSGD iter. 431/499: loss=4.476410345355225, w0=72.80000000000014, w1=12.063995040839462\n",
      "SubSGD iter. 432/499: loss=4.6238172442043535, w0=73.50000000000014, w1=11.932090011928114\n",
      "SubSGD iter. 433/499: loss=4.646219067790271, w0=72.80000000000014, w1=11.503966708700654\n",
      "SubSGD iter. 434/499: loss=4.7837037230398485, w0=72.10000000000014, w1=12.030721334432968\n",
      "SubSGD iter. 435/499: loss=4.707171757045649, w0=72.80000000000014, w1=12.973238828908531\n",
      "SubSGD iter. 436/499: loss=4.465059795917284, w0=73.50000000000014, w1=12.500467158953729\n",
      "SubSGD iter. 437/499: loss=4.521985597325211, w0=72.80000000000014, w1=13.597003920834627\n",
      "SubSGD iter. 438/499: loss=4.438104437778155, w0=73.50000000000014, w1=12.542337230979886\n",
      "SubSGD iter. 439/499: loss=4.514581713432584, w0=72.80000000000014, w1=11.721720897836427\n",
      "SubSGD iter. 440/499: loss=4.716420974838779, w0=73.50000000000014, w1=12.396139737277442\n",
      "SubSGD iter. 441/499: loss=4.541363879447261, w0=74.20000000000014, w1=12.787035576506407\n",
      "SubSGD iter. 442/499: loss=4.539580817599806, w0=73.50000000000014, w1=13.608169375044644\n",
      "SubSGD iter. 443/499: loss=4.429940749298738, w0=74.20000000000014, w1=14.417604218669526\n",
      "SubSGD iter. 444/499: loss=4.554517213239748, w0=73.50000000000014, w1=14.900921804656441\n",
      "SubSGD iter. 445/499: loss=4.5711970806988775, w0=72.80000000000014, w1=13.487925049052437\n",
      "SubSGD iter. 446/499: loss=4.438339149016209, w0=73.50000000000014, w1=12.964130556296068\n",
      "SubSGD iter. 447/499: loss=4.45709356087676, w0=72.80000000000014, w1=13.49489021384868\n",
      "SubSGD iter. 448/499: loss=4.438270187273016, w0=72.10000000000014, w1=13.915657724128758\n",
      "SubSGD iter. 449/499: loss=4.525297030080281, w0=72.80000000000014, w1=14.440395054834628\n",
      "SubSGD iter. 450/499: loss=4.499311431449652, w0=73.50000000000014, w1=15.022458496678041\n",
      "SubSGD iter. 451/499: loss=4.596409671477907, w0=74.20000000000014, w1=15.326326359914898\n",
      "SubSGD iter. 452/499: loss=4.731596669651087, w0=74.90000000000015, w1=15.627669421088799\n",
      "SubSGD iter. 453/499: loss=4.937532706093984, w0=74.20000000000014, w1=16.491034985849257\n",
      "SubSGD iter. 454/499: loss=5.103181212290892, w0=73.50000000000014, w1=16.40369726185401\n",
      "SubSGD iter. 455/499: loss=5.013491305911197, w0=74.20000000000014, w1=15.715867807930454\n",
      "SubSGD iter. 456/499: loss=4.8392695578520994, w0=73.50000000000014, w1=15.840429423683863\n",
      "SubSGD iter. 457/499: loss=4.817621233876502, w0=74.20000000000014, w1=16.39509683723642\n",
      "SubSGD iter. 458/499: loss=5.067260744992432, w0=74.90000000000015, w1=16.49494330541573\n",
      "SubSGD iter. 459/499: loss=5.221337881551075, w0=74.20000000000014, w1=16.90580094183168\n",
      "SubSGD iter. 460/499: loss=5.2682513136947104, w0=73.50000000000014, w1=17.361424957536624\n",
      "SubSGD iter. 461/499: loss=5.414233674609562, w0=74.20000000000014, w1=16.20760059119206\n",
      "SubSGD iter. 462/499: loss=4.999449204942483, w0=74.90000000000015, w1=16.643684255654723\n",
      "SubSGD iter. 463/499: loss=5.277079531810954, w0=74.20000000000014, w1=17.08212850834182\n",
      "SubSGD iter. 464/499: loss=5.342878524753957, w0=73.50000000000014, w1=18.11862310355558\n",
      "SubSGD iter. 465/499: loss=5.780970708900136, w0=74.20000000000014, w1=18.137858384828796\n",
      "SubSGD iter. 466/499: loss=5.838725184706437, w0=74.90000000000015, w1=18.72159534317683\n",
      "SubSGD iter. 467/499: loss=6.240797664987402, w0=75.60000000000015, w1=18.33782092607935\n",
      "SubSGD iter. 468/499: loss=6.19326866468497, w0=74.90000000000015, w1=18.639290598660857\n",
      "SubSGD iter. 469/499: loss=6.1974719857930625, w0=75.60000000000015, w1=18.511376290712285\n",
      "SubSGD iter. 470/499: loss=6.2803351854787515, w0=76.30000000000015, w1=18.295477213344864\n",
      "SubSGD iter. 471/499: loss=6.37610991837986, w0=75.60000000000015, w1=17.81934614906674\n",
      "SubSGD iter. 472/499: loss=5.945244825945016, w0=74.90000000000015, w1=17.1926466537899\n",
      "SubSGD iter. 473/499: loss=5.500623964079965, w0=74.20000000000014, w1=16.309113837473284\n",
      "SubSGD iter. 474/499: loss=5.035775235035162, w0=74.90000000000015, w1=16.564024262249053\n",
      "SubSGD iter. 475/499: loss=5.2469715535350785, w0=74.20000000000014, w1=15.704266294800698\n",
      "SubSGD iter. 476/499: loss=4.835817418722168, w0=73.50000000000014, w1=15.22171848140228\n",
      "SubSGD iter. 477/499: loss=4.642478701196429, w0=72.80000000000014, w1=14.729208151640188\n",
      "SubSGD iter. 478/499: loss=4.545405749725706, w0=73.50000000000014, w1=14.286128274983035\n",
      "SubSGD iter. 479/499: loss=4.474498214523905, w0=72.80000000000014, w1=14.39370553784049\n",
      "SubSGD iter. 480/499: loss=4.493036932291208, w0=73.50000000000014, w1=13.778119705665706\n",
      "SubSGD iter. 481/499: loss=4.434384200918085, w0=74.20000000000014, w1=14.525915655280222\n",
      "SubSGD iter. 482/499: loss=4.569954181704469, w0=73.50000000000014, w1=15.644639282322185\n",
      "SubSGD iter. 483/499: loss=4.757533352770987, w0=74.20000000000014, w1=15.48561087552767\n",
      "SubSGD iter. 484/499: loss=4.773479750659782, w0=74.90000000000015, w1=15.359356897509587\n",
      "SubSGD iter. 485/499: loss=4.86578600030962, w0=75.60000000000015, w1=15.821002060373276\n",
      "SubSGD iter. 486/499: loss=5.1782644314329564, w0=74.90000000000015, w1=16.496062980625183\n",
      "SubSGD iter. 487/499: loss=5.221749823220404, w0=75.60000000000015, w1=15.825379357353453\n",
      "SubSGD iter. 488/499: loss=5.179544838356573, w0=74.90000000000015, w1=14.870370101739015\n",
      "SubSGD iter. 489/499: loss=4.756788623142967, w0=75.60000000000015, w1=15.06702575413772\n",
      "SubSGD iter. 490/499: loss=4.986767858731492, w0=74.90000000000015, w1=13.846527194502604\n",
      "SubSGD iter. 491/499: loss=4.634830312402253, w0=75.60000000000015, w1=13.981075917466141\n",
      "SubSGD iter. 492/499: loss=4.840792170294218, w0=74.90000000000015, w1=13.941985344729156\n",
      "SubSGD iter. 493/499: loss=4.639393396884257, w0=74.20000000000014, w1=13.917041996905695\n",
      "SubSGD iter. 494/499: loss=4.505909332249018, w0=74.90000000000015, w1=12.912338042722128\n",
      "SubSGD iter. 495/499: loss=4.659602875793722, w0=74.20000000000014, w1=13.670836101727541\n",
      "SubSGD iter. 496/499: loss=4.495618960027738, w0=74.90000000000015, w1=12.394912272795185\n",
      "SubSGD iter. 497/499: loss=4.728304745586622, w0=74.20000000000014, w1=13.245177511326935\n",
      "SubSGD iter. 498/499: loss=4.500973869130256, w0=73.50000000000014, w1=13.085738414621426\n",
      "SubSGD iter. 499/499: loss=4.446441685045502, w0=72.80000000000014, w1=13.44245132657941\n",
      "SubSGD: execution time=0.036 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43b13362ed24c958f5f9d047f424925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses, subsgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c489d8217a86cc4c7cc284413e460a9aa122dda169e247fbe22565efc9ab930"
   }
  },
  "widgets": {
   "state": {
    "d2b2c3aea192430e81437f33ba0b0e69": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e4a6a7a70ccd42ddb112989c04f2ed3f": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
